[
  {
    "objectID": "workshop/preview/intro-to-pytorch.html",
    "href": "workshop/preview/intro-to-pytorch.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session introduces PyTorch, one of the most popular deep learning frameworks, known for its flexibility and ease of use. Participants will gain hands-on experience with PyTorch‚Äôs core functionalities and apply them to a sample dataset, setting the stage for a subsequent hands-on session. The goal is to arm participants with the essential knowledge and confidence required to begin utilizing PyTorch in their deep learning endeavors, ensuring they‚Äôre well-prepared for practical application and further exploration.\n\n\n\n\nIntroduction to PyTorch\nUnderstanding PyTorch‚Äôs core functionalities\nWorking with data in PyTorch\nBuilding a simple neural network in PyTorch\nTraining a model\nEvaluating a model\nConclusion and preparing for hands-on session\n\n\n\n\n\nhttps://pytorch.org\nhttps://pytorch.org/tutorials/",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Introduction to PyTorch: core functionalities and advantages"
    ]
  },
  {
    "objectID": "workshop/preview/intro-to-pytorch.html#goal",
    "href": "workshop/preview/intro-to-pytorch.html#goal",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session introduces PyTorch, one of the most popular deep learning frameworks, known for its flexibility and ease of use. Participants will gain hands-on experience with PyTorch‚Äôs core functionalities and apply them to a sample dataset, setting the stage for a subsequent hands-on session. The goal is to arm participants with the essential knowledge and confidence required to begin utilizing PyTorch in their deep learning endeavors, ensuring they‚Äôre well-prepared for practical application and further exploration.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Introduction to PyTorch: core functionalities and advantages"
    ]
  },
  {
    "objectID": "workshop/preview/intro-to-pytorch.html#outline",
    "href": "workshop/preview/intro-to-pytorch.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Introduction to PyTorch\nUnderstanding PyTorch‚Äôs core functionalities\nWorking with data in PyTorch\nBuilding a simple neural network in PyTorch\nTraining a model\nEvaluating a model\nConclusion and preparing for hands-on session",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Introduction to PyTorch: core functionalities and advantages"
    ]
  },
  {
    "objectID": "workshop/preview/intro-to-pytorch.html#reference",
    "href": "workshop/preview/intro-to-pytorch.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "https://pytorch.org\nhttps://pytorch.org/tutorials/",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Introduction to PyTorch: core functionalities and advantages"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-pytorch.html",
    "href": "workshop/preview/hands-on-lab-pytorch.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This hands-on lab session is designed to provide participants with practical experience using PyTorch to build, train, and evaluate neural network models. Participants will work through guided exercises that reinforce the concepts introduced in the previous session, applying PyTorch to real-world datasets relevant to Arctic research. By the end of this session, participants will have a solid understanding of how to implement deep learning models using PyTorch, empowering them to tackle their own projects with confidence.\n\n\n\n\nRecap of PyTorch core functionalities\nGuided exercise 1: working with real-world datasets\nGuided exercise 2: building a simple neural network\nGuided exercise 3: training and evaluating the model\nTroubleshooting and optimization tips\nConclusion and Q&A\n\n\n\n\n\nhttps://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\nhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\nhttps://pytorch.org/tutorials/beginner/vt_tutorial.html",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: PyTorch"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-pytorch.html#overview",
    "href": "workshop/preview/hands-on-lab-pytorch.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This hands-on lab session is designed to provide participants with practical experience using PyTorch to build, train, and evaluate neural network models. Participants will work through guided exercises that reinforce the concepts introduced in the previous session, applying PyTorch to real-world datasets relevant to Arctic research. By the end of this session, participants will have a solid understanding of how to implement deep learning models using PyTorch, empowering them to tackle their own projects with confidence.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: PyTorch"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-pytorch.html#outline",
    "href": "workshop/preview/hands-on-lab-pytorch.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Recap of PyTorch core functionalities\nGuided exercise 1: working with real-world datasets\nGuided exercise 2: building a simple neural network\nGuided exercise 3: training and evaluating the model\nTroubleshooting and optimization tips\nConclusion and Q&A",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: PyTorch"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-pytorch.html#reference",
    "href": "workshop/preview/hands-on-lab-pytorch.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\nhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\nhttps://pytorch.org/tutorials/beginner/vt_tutorial.html",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: PyTorch"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-foundation-models.html",
    "href": "workshop/preview/hands-on-lab-foundation-models.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "The hands-on lab on foundation models will focus on building and applying small-scale foundation models for some example use cases. The main goal of this 1-hour session will be to get more familiarized with foundation models and in interacting with them.\n\n\n\n\nImage Segmentation using Segment Anything Model (SAM)\nChatbot using LLMs + RAG\n\n\n\n\n\nSegment Anything\nSegment Anything Notebook",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: foundation models"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-foundation-models.html#overview",
    "href": "workshop/preview/hands-on-lab-foundation-models.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "The hands-on lab on foundation models will focus on building and applying small-scale foundation models for some example use cases. The main goal of this 1-hour session will be to get more familiarized with foundation models and in interacting with them.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: foundation models"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-foundation-models.html#outline",
    "href": "workshop/preview/hands-on-lab-foundation-models.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Image Segmentation using Segment Anything Model (SAM)\nChatbot using LLMs + RAG",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: foundation models"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-foundation-models.html#references",
    "href": "workshop/preview/hands-on-lab-foundation-models.html#references",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Segment Anything\nSegment Anything Notebook",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: foundation models"
    ]
  },
  {
    "objectID": "workshop/preview/exploring-advanced-neural-networks.html",
    "href": "workshop/preview/exploring-advanced-neural-networks.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session focuses on advanced neural networks, specifically targeting semantic segmentation. Participants will delve into models such as Fully Convolutional Networks (FCNs) and U-Net, learning how these networks are structured, how they function, and how they can be applied to accurately segment and label each pixel of an image according to the object it represents. The goal is to deepen participants‚Äô understanding of the technical foundations and practical applications of semantic segmentation, equipping them with the skills needed for hands-on implementation and exploration of its real-world utility, particularly in the context of Arctic research.\n\n\n\n\nIntroduction to semantic segmentation\nOverview of key models: Fully Convolutional Networks (FCNs) and U-Net\nDetailed architecture and functionality\nApplications in Arctic research: case studies\nConclusion and Q&A\n\n\n\n\n\nRonneberger, Olaf, Philipp Fischer, and Thomas Brox. ‚ÄúU-net: Convolutional networks for biomedical image segmentation.‚Äù Medical image computing and computer-assisted intervention‚ÄìMICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18. Springer International Publishing, 2015. https://arxiv.org/abs/1505.04597\nMinaee, Shervin, et al.¬†‚ÄúImage segmentation using deep learning: A survey.‚Äù IEEE transactions on pattern analysis and machine intelligence 44.7 (2021): 3523-3542. http://www.arxiv.org/abs/2001.05566",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Exploring advanced neural networks: semantic segmentation"
    ]
  },
  {
    "objectID": "workshop/preview/exploring-advanced-neural-networks.html#overview",
    "href": "workshop/preview/exploring-advanced-neural-networks.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session focuses on advanced neural networks, specifically targeting semantic segmentation. Participants will delve into models such as Fully Convolutional Networks (FCNs) and U-Net, learning how these networks are structured, how they function, and how they can be applied to accurately segment and label each pixel of an image according to the object it represents. The goal is to deepen participants‚Äô understanding of the technical foundations and practical applications of semantic segmentation, equipping them with the skills needed for hands-on implementation and exploration of its real-world utility, particularly in the context of Arctic research.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Exploring advanced neural networks: semantic segmentation"
    ]
  },
  {
    "objectID": "workshop/preview/exploring-advanced-neural-networks.html#outline",
    "href": "workshop/preview/exploring-advanced-neural-networks.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Introduction to semantic segmentation\nOverview of key models: Fully Convolutional Networks (FCNs) and U-Net\nDetailed architecture and functionality\nApplications in Arctic research: case studies\nConclusion and Q&A",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Exploring advanced neural networks: semantic segmentation"
    ]
  },
  {
    "objectID": "workshop/preview/exploring-advanced-neural-networks.html#reference",
    "href": "workshop/preview/exploring-advanced-neural-networks.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. ‚ÄúU-net: Convolutional networks for biomedical image segmentation.‚Äù Medical image computing and computer-assisted intervention‚ÄìMICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18. Springer International Publishing, 2015. https://arxiv.org/abs/1505.04597\nMinaee, Shervin, et al.¬†‚ÄúImage segmentation using deep learning: A survey.‚Äù IEEE transactions on pattern analysis and machine intelligence 44.7 (2021): 3523-3542. http://www.arxiv.org/abs/2001.05566",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Exploring advanced neural networks: semantic segmentation"
    ]
  },
  {
    "objectID": "workshop/preview/ai-ethics.html",
    "href": "workshop/preview/ai-ethics.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Review FAIR and CARE Principles, and their relevance to data ethics. Examine how ethical considerations are shared and considered at the Arctic Data Center. Discuss ethical considerations in machine learning.\nNotes: see https://learning.nceas.ucsb.edu/2022-09-arctic/sections/14-data-ethics.html",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI ethics"
    ]
  },
  {
    "objectID": "workshop/preview/ai-ethics.html#reference",
    "href": "workshop/preview/ai-ethics.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Review FAIR and CARE Principles, and their relevance to data ethics. Examine how ethical considerations are shared and considered at the Arctic Data Center. Discuss ethical considerations in machine learning.\nNotes: see https://learning.nceas.ucsb.edu/2022-09-arctic/sections/14-data-ethics.html",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI ethics"
    ]
  },
  {
    "objectID": "webinars/upcoming-webinars.html",
    "href": "webinars/upcoming-webinars.html",
    "title": "Upcoming Webinars",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "webinars/index.html",
    "href": "webinars/index.html",
    "title": "Webinars",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "webinars/index.html#upcoming-webinars",
    "href": "webinars/index.html#upcoming-webinars",
    "title": "Webinars",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "webinars/index.html#past-webinars",
    "href": "webinars/index.html#past-webinars",
    "title": "Webinars",
    "section": "Past Webinars",
    "text": "Past Webinars\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nSemantic Enrichment and LLM-Driven Analytics to the Mindat Open Data Portal\n\n\n\n\n\n\n\n\nAug 18, 2025\n\n\nDr.¬†Xiaogang Ma, Associate Professor of Computer Science, University of Idaho\n\n\n\n\n\n\n\n\n\n\n\n\nInfrastructure Mapping with AI\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nBessie Lea Weston, NSF NNA Project, Meq Unguvatarkarput  Dr.¬†Chandi Witharana, University of Connecticut  Elias Manos, University of Connecticut  Dr.¬†Wenwen Li, Arizona State University\n\n\n\n\n\n\n\n\n\n\n\n\nHyper-Spatial Remote Sensing\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nDr.¬†Compton Tucker, National Aeronautics and Space Administration (NASA)\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Neural Representations of our Planet from Earth Observation Data\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nDr.¬†Konstantin Klemmer, Microsoft Research\n\n\n\n\n\n\n\n\n\n\n\n\nA Framework for Building and Finetuning Geospatial Foundation Models\n\n\n\n\n\n\n\n\nNov 13, 2023\n\n\nDr.¬†Daniela Szwarcman, IBM ResearchDr.¬†Paolo Fraccaro, IBM Research\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "webinars/content/091224-hyper-spatial-remote-sensing.html",
    "href": "webinars/content/091224-hyper-spatial-remote-sensing.html",
    "title": "Hyper-Spatial Remote Sensing",
    "section": "",
    "text": "Abstract\nLarge volumes of sub-meter commercial satellite data coupled with high performance computing & machine learning provide new insights for Earth Science. This includes digital elevation retrievals at the meter x-y scale, the ability to map trees & bushes over large areas with high accuracy, and the possibility to map other features with high accuracy using machine learning. Several examples of these new possibilities will be discussed & illustrated with recent successful studies.\n\n\nDate and Time\nSeptember 12, 2024, 1:00 - 2:00 PM EST\n\n\nLink\nhttps://asu.zoom.us/j/84337093581\n\n\nSpeaker Biography\nDr.¬†Tucker specializes in studying the earth with satellite data. He was among the first researchers to employ coarse-resolution satellite data to exploit the time domain for studying global photosynthesis on land, determining land cover, monitoring droughts, providing famine early warning, and predicting ecologically-coupled disease outbreaks. He has also used large quantities of Landsat data to study forest condition, deforestation, and forest fragmentation in temperate, subtropical, and tropical forests; and to study glacier extent. From 2005 to 2010, he was on NASA detail to the U.S. Global Change Program where he was the co-chairperson of two Interagency Working Groups, for Observations and for Land Use and Land Cover Change. He was active in NASA‚Äôs Space Archaeology Program and has conducted ground-based radar and magnetic surveys at Troy, the Granicus River Valley, and Gordion in Turkey, with University of Pennsylvania projects working at these locations from 2001 to 2012. Since 2014, he has been active in mapping land and forest degradation and attempting to quantify arid and semi-arid woody biomass using Landsat, MODIS, and large volumes of commercial satellite data. More recently, Tucker and colleagues have mastered mapping billions of trees and converting these into carbon at tree-level using machine learning coupled to high-performance computing. https://science.gsfc.nasa.gov/sci/bio/compton.j.tucker\n\n\nRecording"
  },
  {
    "objectID": "webinars/content/062424-neural-representations-earth-observation.html",
    "href": "webinars/content/062424-neural-representations-earth-observation.html",
    "title": "Learning Neural Representations of our Planet from Earth Observation Data",
    "section": "",
    "text": "Abstract\nEarth observation data captures the natural and built environment of our planet. It comes in different forms, from satellite images to in-situ measurements, but can be mapped into the same geometric space: the sphere of planet Earth. It can be crucial in supporting decision making in the private and public sector alike, from improving flood resilience to forecasting crop yields. But making sense of the vast amounts of Earth observation data is difficult as it is often unstructured, unlabeled and multi-modal. Neural networks have emerged as a powerful tool for processing such large quantities of unstructured data but are not equipped to handle the spatial and temporal dependencies and spherical geometry of Earth observation data. In this talk, I will present a new class of neural network models purpose-built for Earth observation data: geographic location encoders. These models combine the scalability of neural networks with geospatial domain knowledge and traditional intuitions from geodesy and spatial statistics. I will highlight how location encoders can be used for fast and accurate predictive modeling on the sphere, with applications in climate modeling and species distribution modeling. I will then present means of training location encoders in the absence of labels‚Äîusing globally distributed satellite imagery and contrastive self-supervised learning. The resulting pretrained location encoders produce general-purpose location embeddings that learn the natural and physical characteristics of locations around the world. These embeddings are powerful features in downstream modeling and can help tackle long-standing challenges in geospatial machine learning such as geographic distribution shift. Finally, I will outline future challenges in AI for Earth and present an ambitious goal: ‚Äúdigitally twinning‚Äù our planet with the support of large-scale, self-supervised learning and Earth observation data.\n\n\nDate and Time\nJune 24, 2024, 1:00 - 2:00 PM EST\n\n\nSpeaker Biography\nKonstantin Klemmer is a postdoctoral researcher at Microsoft Research New England and part of the Machine Learning and Statistics group. His research focuses on the representation of geographic phenomena in machine learning methods, particularly in neural networks. Konstantin‚Äôs recent work includes the integration of notions of spatial dependency into neural networks and the unsupervised training of location encoders that learn characteristics of a given location and can be deployed in various downstream tasks. His work is motivated by real-world challenges such as climate change and increasing urbanization, combining technical and methodological research with application and deployment studies. Konstantin has a PhD in Computer Science and Urban Science from the University of Warwick and spent time as a visiting student at NYU, as an Enrichment student at the Alan Turing Institute and as a Beyond Fellow at TUM and DLR. He also holds a Master‚Äôs in Transportation from Imperial College London and University College London. Website: https://konstantinklemmer.github.io\n\n\nRecording"
  },
  {
    "objectID": "people/core-project-team.html",
    "href": "people/core-project-team.html",
    "title": "Core Project Team",
    "section": "",
    "text": "Wenwen Li\n\n\nProject Lead  Principal Investigator, NSF Award 2230034  Professor  Arizona State University  wenwen@asu.edu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnna Liljedahl\n\n\nPrincipal Investigator, NSF Award 2230035 Associate Scientist  Woodwell Climate Research Center aliljedahl@woodwellclimate.org \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMatthew Jones\n\n\nCo-Principal Investigator, NSF Award 2230034 Director of Research and Development, Informatics  National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara jones@nceas.ucsb.edu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKenton McHenry\n\n\nCo-Principal Investigator, NSF Award 2230035 Associate Director of Software  National Center for Supercomputing Applications mchenry@illinois.edu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChia-Yu Hsu\n\n\nSenior Personnel Research Professional  Arizona State University chsu53@asu.edu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatricia Solis\n\n\nSenior Personnel Executive Director, Knowledge Exchange for Resilience  Arizona State University patricia.solis@asu.edu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLuigi Marini\n\n\nSenior Personnel Lead Research Software Engineer  National Center for Supercomputing Applications lmarini@illinois.edu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCarmen Galaz Garc√≠a\n\n\nData Scientist National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nXiao Chen\n\n\nPhD student Arizona State University xchen414@asu.edu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSizhe Wang\n\n\nPhD student Arizona State University wsizhe@asu.edu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKate Hohman Billmeier\n\n\nExternal Evaluator Wellspring Group Consulting, LLC kate@wellspringalaska.com \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaleb Billmeier\n\n\nExternal Evaluator Wellspring Group Consulting, LLC caleb@wellspringalaska.com \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMinu Mathew\n\n\nResearch Software Engineer  National Center for Supercomputing Applications(NCSA) at University of Illinois Urbana Champaign  minum@illinois.edu  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSandeep Puthanveetil Satheesan\n\n\nSenior Research Software Engineer  National Center for Supercomputing Applications, University of Illinois Urbana-Champaign  sandeeps@illinois.edu  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBen Galewsky\n\n\nSr.¬†Research Software Engineer  National Center for Supercomputing Applications(NCSA) at University of Illinois Urbana Champaign  bengal1@illinois.edu  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNicole Greco\n\n\nCommunity Engagement & Outreach Coordinator  National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara  greco@nceas.ucsb.edu  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlyona Kosobokova\n\n\nSenior Research Software Engineer  National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJim Regetz\n\n\nDirector of Research Software Engineering  National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara  regetz@nceas.ucsb.edu  \n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people/content/xiao_chen.html",
    "href": "people/content/xiao_chen.html",
    "title": "Xiao Chen",
    "section": "",
    "text": "I am a PhD student in GIScience interested in GeoAI and web-based visualization."
  },
  {
    "objectID": "people/content/sizhe_wang.html",
    "href": "people/content/sizhe_wang.html",
    "title": "Sizhe Wang",
    "section": "",
    "text": "I am a PhD student in computer science specializing in cyberinfrastructure, 4D data visualization, information retrieval, parallel computing, and spatial data analysis."
  },
  {
    "objectID": "people/content/patricia_solis.html",
    "href": "people/content/patricia_solis.html",
    "title": "Patricia Solis",
    "section": "",
    "text": "I am Executive Director of the Knowledge Exchange for Resilience at Arizona State University, a campus-wide effort to link multi-sector community needs with research innovations in building community resilience."
  },
  {
    "objectID": "people/content/minu_mathew.html",
    "href": "people/content/minu_mathew.html",
    "title": "Minu Mathew",
    "section": "",
    "text": "I‚Äôm a Research Software Engineer at the National Center for Supercomputing Applications(NCSA) at University of Illinois Urbana Champaign. My primary interests are in the field of ML/AI with a focus in NLP. Having a background in Computer Science and Wireless communication, I try to utilize the knowledge gained across multiple verticals to deliver better solutions and software. At NCSA, I work on multiple projects ranging from implementing LLM agents for RNA Sequencing tasks to development of a cloud native data management framework. Outside of work, I like badminton, swimming, traveling, painting and attending concerts."
  },
  {
    "objectID": "people/content/luigi_marini.html",
    "href": "people/content/luigi_marini.html",
    "title": "Luigi Marini",
    "section": "",
    "text": "I am a lead research software engineer at the National Center for Supercomputing Applications (NCSA)."
  },
  {
    "objectID": "people/content/kate_hohman_billmeier.html",
    "href": "people/content/kate_hohman_billmeier.html",
    "title": "Kate Hohman Billmeier",
    "section": "",
    "text": "Together with Caleb, Kate helped found Wellspring Group Consulting. Kate believes that local voices should help determine, design, and control projects that enhance the well-being of their communities. In co-founding Wellspring Group Consulting, Kate envisions working with communities to build on their existing assets to connect, strengthen, and grow their capacity to do good work.\nSince 2010, Kate has taught Political Science and Women‚Äôs Studies in the University of Alaska system. Kate also worked at the Institute of Social and Economic Research as part of a monitoring and evaluation team for a multi-year federally-funded health project in Alaska. She has worked as a consultant in rural Alaska conducting studies on the impact of development projects on subsistence practices. Prior to her work in Alaska, Kate worked at an international INGO focused on helping women living in conflict-affected countries recover from war.\nKate received her BA in Political Science and International Affairs from the University of Mary Washington and her MA in Women‚Äôs Studies from The George Washington University. She received her PhD in Development Studies from the School of Oriental and African Studies, University of London in 2014.\nKate lives in Seldovia, Alaska with her family."
  },
  {
    "objectID": "people/content/chiayu_hsu.html",
    "href": "people/content/chiayu_hsu.html",
    "title": "Chia-Yu Hsu",
    "section": "",
    "text": "I am a research professional specializing in deep learning and computer vision for remote sensing image analysis."
  },
  {
    "objectID": "people/content/ben_galewsky.html",
    "href": "people/content/ben_galewsky.html",
    "title": "Ben Galewsky",
    "section": "",
    "text": "After working for several years as an IT Consultant in industry I‚Äôve happily switched to a career in research software engineering, which I think of as IT Consulting for Science! I‚Äôm currently a Senior Research Software Engineer at the National Center for Supercomputing Applications (NCSA) at the University of Illinois Urbana Champaign. I work with researchers to understand their needs and design software solutions to help advance their research goals. I‚Äôm particularly intersted in data management and machine learning operations."
  },
  {
    "objectID": "people/content/alyona_kosobokova.html",
    "href": "people/content/alyona_kosobokova.html",
    "title": "Alyona Kosobokova",
    "section": "",
    "text": "Alyona is a Senior Research Software Engineer with extensive experience building and architecting infrastructure for leading companies such as Disney, Airtable and Hulu. She has also provided strategic guidance for two successful AI startups. Alyona holds a Bachelor‚Äôs degree in Computational Astrophysics and is currently pursuing a Master‚Äôs in Applied Artificial Intelligence. Throughout her career, she has collaborated with various research groups, including UCSB, UCSC, Harvard, and SFSU astrophysics teams. Beyond engineering and science, check out her silly sciencepop Youtube Channel: Dork Matter Girl."
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "News",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAnnouncing the 2025 Workshop: Scaling Impact in AI/ML Education for Arctic Research\n\n\n\n\n\n\n\n\nJun 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nNew review paper on AI in Arctic Sea Ice Remote Sensing!\n\n\n\n\n\n\n\n\nOct 30, 2024\n\n\nWenwen Li\n\n\n\n\n\n\n\n\n\n\n\n\nArctic researchers dive into AI and ML for transformative science in the first Cyber2A workshop\n\n\n\n\n\n\n\n\nOct 29, 2024\n\n\nNicole Greco\n\n\n\n\n\n\n\n\n\n\n\n\nGoogle.org‚Äôs new grant to help track permafrost thaw\n\n\n\n\n\n\n\n\nAug 10, 2023\n\n\nBrigitte Hoyer Gosselink\n\n\n\n\n\n\n\n\n\n\n\n\nThe multi-institution project received $5M in funding from Google.org to better understand Arctic permafrost thaw\n\n\n\n\n\n\n\n\nAug 10, 2023\n\n\nDavid Rozul\n\n\n\n\n\n\n\n\n\n\n\n\nASU AI project analyzes big data to help analysts find solutions to Arctic warming\n\n\n\n\n\n\n\n\nMay 7, 2023\n\n\nDolores Tropiano\n\n\n\n\n\n\n\n\n\n\n\n\nWinners announced for the 1st GeoAI Martian Challenge!\n\n\n\n\n\n\n\n\nMay 1, 2023\n\n\nWenwen Li\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "news/content/102924_cyber2a_workshop.html",
    "href": "news/content/102924_cyber2a_workshop.html",
    "title": "Arctic researchers dive into AI and ML for transformative science in the first Cyber2A workshop",
    "section": "",
    "text": "Arctic researchers gather in Santa Barbara, CA for the first NSF Cyber2A workshop, exploring AI and ML applications in polar science.\n\n\nLast week, 20 Arctic researchers gathered in Santa Barbara, CA for the first NSF Cyber2A workshop to learn more about incorporating artificial intelligence (AI) and machine learning (ML) techniques into their research. Topics covered in this workshop included AI fundamentals and tools, AI-ready data, data annotation, neural networks and deep learning, AI ethics, reproducibility, and more. Participant‚Äôs research and experiences varied widely. While some researchers are focusing on sea ice and ice-sheet dynamics, others are studying similarities between the Arctic and otherworldly bodies such as Europa. All participants had one thing in common- their interest in using machine learning and artificial intelligence to further their research. Interested in learning more about using ML and AI in your research? Visit the Cyber2A course book to access all open-source materials from the workshop. We are enhancing our step-by-step AI training materials with lectures and code to support self-paced learning and lifelong learners, wherever you are in the world. Check out our website for updates and stay tuned for our 2025 training!\n\n\n\n\n\n\n\n\n\n\n\nCyber2A workshop participants and instructors celebrate a successful week of hands-on learning in AI and ML for Arctic research."
  },
  {
    "objectID": "news/content/081023_google_org_grant.html",
    "href": "news/content/081023_google_org_grant.html",
    "title": "Google.org‚Äôs new grant to help track permafrost thaw",
    "section": "",
    "text": "Permafrost thaw\n\n\nToday we‚Äôre announcing a $5 million grant and Google.org Fellowship to Woodwell Climate Research Center to help them deploy satellite imagery and AI technology to track permafrost thaw in near real-time. Faster insights about permafrost‚Äôs contribution to global warming will not only help inform international climate policy, it will help the 5 million people currently living in the Arctic adapt to their quickly changing landscape and reduce costs associated with infrastructure damage (estimated to be in the billions).\nPreviously, permafrost analysis could take years ‚Äî even decades ‚Äî and currently, we only have one-time snapshots of past permafrost thaw. But new AI models can help scientists monitor permafrost thaw monthly by analyzing massive amounts of satellite imagery data to produce seasonal forecasts.\n‚ÄúSpeeding up data analysis in a rapidly shifting global climate is a game changer,‚Äù says Dr.¬†Anna Liljedahl, one of the lead scientists working on the project at Woodwell. ‚ÄúNew geospatial projects like the one we‚Äôll build together can help us better understand permafrost landscapes and the real-time impact of weather changes and extreme weather events.‚Äù\nLearn more about Anna‚Äôs research and other women climate scientists receiving support from Google.org"
  },
  {
    "objectID": "news/content/050723_asu_ai_project.html",
    "href": "news/content/050723_asu_ai_project.html",
    "title": "ASU AI project analyzes big data to help analysts find solutions to Arctic warming",
    "section": "",
    "text": "photo by Andreas Weith, CC BY-SA 4.0, via Wikimedia Commons\n\n\nThe Arctic is facing a climate crisis that‚Äôs threatening the region, its people and the rest of the world. And while solutions to this crisis are available, like many parts of the polar region, they are just out of reach.\nFor years, satellites and drones have collected an avalanche of scientific data from even the most remote and unexplored areas of the Arctic. But the problem is that there is too much information, and it‚Äôs almost impossible to interpret.\nOne Arizona State University professor hopes to change that.\nIn August, Wenwen Li and her partners were awarded a $1 million research grant to help scientists learn to use artificial intelligence to address the pending disaster in the Arctic. Li is the principal investigator on the project.\n‚ÄúThe problem in the Arctic is so urgent,‚Äù said Li, a data scientist trained in computer science and earth system science at ASU. ‚ÄúWe need to resolve it as soon as we possibly can.‚Äù\n\nBig data\nLi, a professor in ASU‚Äôs School of Geographical Sciences and Urban Planning, describes the daunting scale of relevant scientific information as ‚Äúthe big data‚Äù challenge.‚Äù\nThat may be an understatement.\nNASA‚Äôs climate change data repository is expected to have 350 petabytes of data by 2030 ‚Äî the equivalent of about 10 billion single-spaced typewritten pages per day. And the satellite company MaxarTechnologies has more than 125 petabytes of global imagery. (That‚Äôs comparable to the total number of letters delivered by the U.S. Postal Service in 25 years.)\nAnd that‚Äôs just part of the problem.\nAnother element is that the data gathered is often incomprehensible to the scientists that need it most.\nThe computers currently in use by the Arctic science community don‚Äôt have the capacity to secure and interpret data on that scale, and doing so is essential for them to solve the serious problems the Arctic is facing.\n‚ÄúData alone will not help,‚Äù said Li, who directs the Cyberinfrastructure and Computational Intelligence Lab on ASU‚Äôs Tempe campus. ‚ÄúWe need the ability to analyze huge amounts of data and receive useful scientific information from it. This process needs the support of artificial intelligence. But many Arctic scientists do not have the skills needed to work with artificial intelligence.‚Äù\nLi and her partners will use the research grant to develop a cyber training program for Arctic scientists, and those from other disciplines, to access, study and ultimately interpret these complex volumes of data with the use of artificial intelligence.\nThe project, titled ‚ÄúCyber 2A: CyberTraining on AI-driven Analytics for Next Generation Arctic Scientists,‚Äù runs from March 2023 through February 2026.\n‚ÄúThe cutting-edge methods of using artificial-intelligence-driven analytics will give Arctic scientists the opportunity to make exciting new discoveries about what is really happening in the Arctic,‚Äù Li said.\nThe undertaking is a collaboration between Arizona State University; the University of California, Santa Barbara; University of Illinois, Urbana-Champaign; and the Woodwell Climate Research Center. The team is made up of experts in cyberinfrastructure, high-performance computing, artificial intelligence and Arctic science.\n\n\nThe polar problem\nSince 1979, climate change and warming throughout the Arctic are taking place at a rapid rate: four times that of other parts of the world, according to a report from the Finnish Meteorological Institute.\nAnd there is no part of the planet untouched by this warming.\nAs the ice melts throughout the 177.6 trillion square-feet of the region, there is a trickle down effect. Infrastructures once securely built on permafrost, a frozen layer of stable soil, are now sinking.\nThe unstable infrastructure impacts everything from the economy to the ability of animals ‚Äî polar bears, walruses, Arctic foxes, caribou ‚Äî to hunt and retain their habitat.\nAs the ice disappears, so does its reflective powers, allowing the sun‚Äôs energy to enter and be retained by the planet. The melting ice also releases methane, a greenhouse gas, that leads to more global warming. And on and on it goes until it seems that the frozen frontier may soon be facing its final years.\nPredictions in the journal Nature Climate Change say that by 2040, there will be no more ice in the Arctic. And because the Arctic plays an important role in moderating the global climate, it will have dire consequences for the rest of the planet.\nScientists, geologists and others studying these problems cannot keep up with the thaw across the global Arctic and the vast amount of unanalyzed research data associated with it. The result is that informed decisions for policymakers and quick actions are impossible to make.\n\n\nTeam takes on the challenge\nThat‚Äôs where Li and her team come in.\nThe grant will help scientists trained in AI-related analytics to accurately predict real time changes and ultimately find solutions to global warming and climate change in the Arctic.\nThe free training will be in-person, online and through a monthly webinar series and is open to both scientists and educators.\nAn Arctic-AI research network will be established for sharing ideas and resources. And all training materials will be deposited in the Arctic Data Center‚Äôs Learning Hub to ensure access to scientists, professionals and developers in the Arctic science and geoscience domains and beyond.\nInclusivity is a major part of the effort. A recruitment plan is underway to create a strong and diverse STEM research workforce providing opportunities for minorities, economically disadvantaged groups, women, members of the Arctic Indiginous community and more.\n‚ÄúThe cybertaining training grant will empower a new generation of Arctic researchers and leaders in utilizing all the data that is being collected across the Arctic,‚Äù said Anna Liljedahl, co-principal investigator for the project from the Woodwell Climate Research Center. ‚ÄúNot just a handful of data processed close to a decade after it was collected, which is how much of the science is currently operating.‚Äù\nAnd ultimately, Li and her peers hope to do their part in restoring the environmental health of a piece of the planet."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cyber2A",
    "section": "",
    "text": "Cyber2A\n            Arctic-AI Research ‚Ä¢ Science Enabling CI ‚Ä¢  CI Training Activities\n        \n    \n\nImage credit: Shutterstock"
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "Cyber2A",
    "section": "# OBJECTIVES",
    "text": "# OBJECTIVES\n\n\n\n    \n        üåê\n        Expand the Arctic-AI research network\n        This network will serve as an important venue for collecting community input on training needs, to engage and recruit potential trainees, and to cultivate new connections with existing Arctic research communities to achieve collective and broader impacts of the Cyber2A training and education.\n    \n    \n        üéì\n        Develop customized training materials, webinars, in-person workshops\n        This objective aims to help Arctic researchers apply the computational and technical skills necessary to select, use, and create the most suitable AI model for their work.\n    \n    \n        üë•\n        Create a sustainable and scalable learning community\n        All training materials will be refined and developed as self-contained learning modules that can be easily plugged into existing education curricula and be used to support online, self-paced learning.\n    \n\n\n\n\n\n    \n        COLLABORATORS\n        \n        \n            \n                \n                    \n                        \n                        \n                        \n                    \n                \n                \n                    \n                        \n                        \n                        \n                    \n                \n                \n                    \n                        \n                        \n                        \n                    \n                \n                \n                    \n                        \n                        \n                        \n                    \n                \n            \n        \n    \n    \n        SPONSOR"
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Cyber2A",
    "section": "# NEWS",
    "text": "# NEWS\n\n\n\n\n\n\nDate\n\n\n\nCategory\n\n\n\nNews\n\n\n\n\n\n\n\n\n8/18/25\n\n\nWebinar\n\n\nSemantic Enrichment and LLM-Driven Analytics to the Mindat Open Data Portal\n\n\n\n\n\n\n6/2/25\n\n\nNews\n\n\nAnnouncing the 2025 Workshop: Scaling Impact in AI/ML Education for Arctic Research\n\n\n\n\n\n\n4/7/25\n\n\nWebinar\n\n\nInfrastructure Mapping with AI\n\n\n\n\n\n\n10/30/24\n\n\nNews\n\n\nNew review paper on AI in Arctic Sea Ice Remote Sensing!\n\n\n\n\n\n\n10/29/24\n\n\nNews\n\n\nArctic researchers dive into AI and ML for transformative science in the first Cyber2A workshop\n\n\n\n\n\n\n9/12/24\n\n\nWebinar\n\n\nHyper-Spatial Remote Sensing\n\n\n\n\n\n\n6/24/24\n\n\nWebinar\n\n\nLearning Neural Representations of our Planet from Earth Observation Data\n\n\n\n\n\n\n11/13/23\n\n\nWebinar\n\n\nA Framework for Building and Finetuning Geospatial Foundation Models\n\n\n\n\n\n\n8/10/23\n\n\nNews\n\n\nGoogle.org‚Äôs new grant to help track permafrost thaw\n\n\n\n\n\n\n8/10/23\n\n\nNews\n\n\nThe multi-institution project received $5M in funding from Google.org to better understand Arctic permafrost thaw\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "challenge/resources.html",
    "href": "challenge/resources.html",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "A central hub for help, learning materials, and policies for the GeoAI Arctic Mapping Challenge.\n\nüí° Tip: If you‚Äôre new here, start with the Quick Links below.\n\n\n\n\n\n\n\n\nStarter code to load data, train, and format submissions.\n\n\nOpen notebook\n\n\n\n\n\nData description, formats, and visualization gallery.\n\n\nView dataset\n\n\n\n\n\nStep-by-step guide to register, submit, and score.\n\n\nHow to participate\n\n\n\n\n\nTrack your standing and compare approaches.\n\n\nOpen leaderboard\n\n\n\n\n\nAsk questions and share insights with peers.\n\n\nGo to forum\n\n\n\n\n\nEmail the organizing team for help.\n\n\nwenwen@asu.edu\n\n\n\n\n\n\n\n\nCompetition support: wenwen@asu.edu\nTechnical Q&A: Use the CodeBench forum for public questions: https://codebench.com/geoai-rts/forum\n\n\n\n\n\n\n\nBaseline notebook: Includes data loading, visualization, baseline model, and submission formatter.\nSubmission format mini-guide: See Participate ‚Üí Results Format for JSON schema.\n\n\n\n\n\nPyTorch segmentation recipes (Instance/semantic fundamentals) link\nDetectron2 / MaskRCNN quickstarts (for instance masks) link\nGeoTIFF & raster I/O (rasterio, xarray, rioxarray) link\nGeospatial features (GDAL, PROJ, coordinate systems refresher) link\n\n\n\n\n\n\nData Usage\n\nThe dataset is provided for research and competition purposes within this challenge.\nRedistribution of the dataset or derivatives outside the challenge requires permission from the original data owners and curators.\n\nAttribution\n\nWorks or publications using this dataset should cite:\nYang et al., 2023 (dataset) and Li et al., 2025 (baseline model) (see citations below).\n\nSubmissions\n\nPredictions must follow the required submission format and reflect automated model outputs (no manual labeling of test sets).\nExternal data usage, if used, must be documented in your method description.\n\nTeams & Conduct\n\nTeaming is allowed (default max 5 members unless otherwise stated).\nDo not share labels or predictions across different teams.\n\nFollow the CodeBench code of conduct and site terms.\n\nPrivacy\n\nTeam name, institution, and scores may appear on the public leaderboard.\n\nDisqualification\n\nViolations of the rules, data misuse, or attempts to game the leaderboard may result in removal from the competition.\n\n\n\nQuestions about policy? Email wenwen@asu.edu\n\n\n\n\n\nCodeBench Platform: https://codebench.com\n\nLeaderboard: https://codebench.com/geoai-rts/leaderboard\n\nForum: https://codebench.com/geoai-rts/forum\n\nDataset Paper (Yang et al., 2023): https://doi.org/10.1016/j.rse.2023.113495\n\nBaseline Model (Li et al., 2025): https://doi.org/10.1109/JSTARS.2025.3564310\n\n\n\n\nQ1. Where do I download the data?\nA: Register on CodeBench ‚Üí challenge page ‚Üí Download tab. Or see the Dataset Page.\nQ2. What‚Äôs the submission format?\nA: COCO-style JSON (see Participate ‚Üí Results Format). A helper is included in the baseline notebook.\nQ4. Can I keep evaluating after prizes are awarded?\nA: Yes ‚Äî use the Benchmark Phase for continuous, no-award evaluation.\nQ5. Can I use external data?\nA: Yes, but you must document it in your method description.",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "challenge/resources.html#quick-links",
    "href": "challenge/resources.html#quick-links",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Starter code to load data, train, and format submissions.\n\n\nOpen notebook\n\n\n\n\n\nData description, formats, and visualization gallery.\n\n\nView dataset\n\n\n\n\n\nStep-by-step guide to register, submit, and score.\n\n\nHow to participate\n\n\n\n\n\nTrack your standing and compare approaches.\n\n\nOpen leaderboard\n\n\n\n\n\nAsk questions and share insights with peers.\n\n\nGo to forum\n\n\n\n\n\nEmail the organizing team for help.\n\n\nwenwen@asu.edu",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "challenge/resources.html#contact-us",
    "href": "challenge/resources.html#contact-us",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Competition support: wenwen@asu.edu\nTechnical Q&A: Use the CodeBench forum for public questions: https://codebench.com/geoai-rts/forum",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "challenge/resources.html#tutorials-learning-materials",
    "href": "challenge/resources.html#tutorials-learning-materials",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Baseline notebook: Includes data loading, visualization, baseline model, and submission formatter.\nSubmission format mini-guide: See Participate ‚Üí Results Format for JSON schema.\n\n\n\n\n\nPyTorch segmentation recipes (Instance/semantic fundamentals) link\nDetectron2 / MaskRCNN quickstarts (for instance masks) link\nGeoTIFF & raster I/O (rasterio, xarray, rioxarray) link\nGeospatial features (GDAL, PROJ, coordinate systems refresher) link",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "challenge/resources.html#terms-conditions",
    "href": "challenge/resources.html#terms-conditions",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Data Usage\n\nThe dataset is provided for research and competition purposes within this challenge.\nRedistribution of the dataset or derivatives outside the challenge requires permission from the original data owners and curators.\n\nAttribution\n\nWorks or publications using this dataset should cite:\nYang et al., 2023 (dataset) and Li et al., 2025 (baseline model) (see citations below).\n\nSubmissions\n\nPredictions must follow the required submission format and reflect automated model outputs (no manual labeling of test sets).\nExternal data usage, if used, must be documented in your method description.\n\nTeams & Conduct\n\nTeaming is allowed (default max 5 members unless otherwise stated).\nDo not share labels or predictions across different teams.\n\nFollow the CodeBench code of conduct and site terms.\n\nPrivacy\n\nTeam name, institution, and scores may appear on the public leaderboard.\n\nDisqualification\n\nViolations of the rules, data misuse, or attempts to game the leaderboard may result in removal from the competition.\n\n\n\nQuestions about policy? Email wenwen@asu.edu",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "challenge/resources.html#useful-external-resources",
    "href": "challenge/resources.html#useful-external-resources",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "CodeBench Platform: https://codebench.com\n\nLeaderboard: https://codebench.com/geoai-rts/leaderboard\n\nForum: https://codebench.com/geoai-rts/forum\n\nDataset Paper (Yang et al., 2023): https://doi.org/10.1016/j.rse.2023.113495\n\nBaseline Model (Li et al., 2025): https://doi.org/10.1109/JSTARS.2025.3564310",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "challenge/resources.html#frequently-asked-questions",
    "href": "challenge/resources.html#frequently-asked-questions",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Q1. Where do I download the data?\nA: Register on CodeBench ‚Üí challenge page ‚Üí Download tab. Or see the Dataset Page.\nQ2. What‚Äôs the submission format?\nA: COCO-style JSON (see Participate ‚Üí Results Format). A helper is included in the baseline notebook.\nQ4. Can I keep evaluating after prizes are awarded?\nA: Yes ‚Äî use the Benchmark Phase for continuous, no-award evaluation.\nQ5. Can I use external data?\nA: Yes, but you must document it in your method description.",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "challenge/participate.html",
    "href": "challenge/participate.html",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "words from organizers\n\n\n\nGo to the CodeBench Challenge Page.\nClick ‚ÄúJoin Challenge‚Äù.\nSign in using GitHub, Google, or your institutional email.\nAccept the data license agreement before accessing the dataset.\nYou‚Äôre ready to start! üöÄ\n\n\n\n\nOnce registered, you can:\n\nDownload the dataset directly from CodeBench.\nOr visit the Dataset Page for detailed information and visualizations.\n\nDataset Highlights:\n\nRGB + Sentinel-2 multi-spectral imagery.\nHigh-resolution ArcticDEM elevation data.\nCOCO-style instance segmentation annotations.\n\n\n\n\nThe dataset is organized into train and test splits with COCO-style annotations:\ndataset/\n‚îú‚îÄ‚îÄ train/\n‚îÇ   ‚îú‚îÄ‚îÄ images/              # Multi-band GeoTIFFs\n‚îÇ   ‚îú‚îÄ‚îÄ masks/               # Per-instance RTS masks\n‚îÇ   ‚îî‚îÄ‚îÄ annotations.json     # COCO-style labels\n‚îî‚îÄ‚îÄ test/\n    ‚îú‚îÄ‚îÄ images/\n    ‚îî‚îÄ‚îÄ sample_submission.json\n\n\n\nItem\nFormat\nDescription\n\n\n\n\nImagery\n.tif\nMulti-band satellite imagery\n\n\nAnnotations\n.json\nCOCO-style instance segmentation\n\n\nMasks\n.png\nPer-instance RTS masks\n\n\n\n\n\n\nWe provide a baseline notebook to help you get started quickly.\nStarter Kit Includes:\n\nData loading & visualization examples.\nBaseline multimodal GeoAI model from Li et al. (2025).\nSample inference code.\nExample submission formatting.\n\n\n\n\nYour task is to predict per-instance RTS masks using satellite imagery and topographic data.\n\n\n\n\n\n\n\nInput\nOutput\n\n\n\n\nMulti-band satellite imagery (.tif)\nRTS instance segmentation masks\n\n\n\n\n\n\nSubmissions are ranked on CodeBench using the following metrics:\n\n\n\n\n\n\n\n\n\nMetric\nDefinition\nRange\nHigher = Better?\n\n\n\n\nmAP\nMean Average Precision over IoU thresholds\n0‚Äì1\n‚úÖ\n\n\nmAP50\nMean Average Precision over IoU thresholds at 0.5\n0‚Äì1\n‚úÖ\n\n\nmAP75\nMean Average Precision over IoU thresholds at 0.75\n0‚Äì1\n‚úÖ\n\n\nmAP-small\nMean Average Precision over IoU thresholds at 0.5 for small objects\n0‚Äì1\n‚úÖ\n\n\nmAP-medium\nMean Average Precision over IoU thresholds at 0.5 for medium objects\n0‚Äì1\n‚úÖ\n\n\nmAP-large\nMean Average Precision over IoU thresholds at 0.5 for large objects\n0‚Äì1\n‚úÖ\n\n\n\n\nPrimary ranking is based on mAP.\n\n\n\n\nYour submission must follow the CodeBench COCO-style JSON format.\nSubmission Folder Structure:\nsubmission/\n‚îú‚îÄ‚îÄ predictions/\n‚îÇ   ‚îú‚îÄ‚îÄ image_001.json\n‚îÇ   ‚îú‚îÄ‚îÄ image_002.json\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ submission.json\nExample submission.json:\n[\n  {\n    \"image_id\": \"image_001\",\n    \"category_id\": 1,\n    \"segmentation\": [ ... ],\n    \"score\": 0.93\n  },\n  {\n    \"image_id\": \"image_002\",\n    \"category_id\": 1,\n    \"segmentation\": [ ... ],\n    \"score\": 0.87\n  }\n]\n\n‚ö†Ô∏è Important: Submissions that do not follow this format will be automatically rejected.\n\n\n\n\n\nTrain your model locally.\nGenerate predictions for the test set.\nPackage predictions in the required submission format.\nCompress into a .zip file.\nUpload to CodeBench Submissions.\nCheck your score on the leaderboard.\n\n\n\n\nThe competition consists of two phases:\n\n\n\n\n\n\n\n\n\nPhase\nTimeline\nDescription\nAwards\n\n\n\n\nChallenge Phase\nSep 09 ‚Üí Nov 30, 2025\nCompete with others, submit predictions, improve models\nüèÖ Yes\n\n\nBenchmark Phase\nStarts Dec 01, 2025\nEvaluate models freely, test reproducibility, no awards\n‚ùå No\n\n\n\n\nChallenge Phase ‚Üí Compete for prizes and leaderboard positions.\nBenchmark Phase ‚Üí Keep testing your models after the official challenge ends.\n\n\n\n\n\n\n\nEvent\nDate\n\n\n\n\nCompetition Opens\nSep 09, 2025\n\n\nDataset Released\nSep 09, 2025\n\n\nFinal Submission\nNov 30, 2025\n\n\nWinners Announced\nDec 15, 2025\n\n\nBenchmark Phase Starts\nDec 01, 2025\n\n\n\n\n\n\n\n\nThe competition is open to everyone, including students, academics, and industry professionals. We encourage participants from diverse backgrounds in computer science, remote sensing, geoscience, and related fields to form teams and compete.\n\n\n\n\nEach team can consist of 1 to 5 members.\nEach team is limited to 2 submissions per day and 100 submissions in .\nThe use of external data is permitted. Please see the Codabench page for specifics.\nCode for the top-performing models must be submitted for verification to be eligible for awards.\nFor a complete list of rules, please visit the competition page on Codabench.\n\n\n\n\nPrizes will be awarded to the top-performing teams based on the final leaderboard standings.\n\n1st Place: 1,000 USD\n2nd Place: 500 USD\n3rd Place: 200 USD\n\n\n\n\n\n\nCodeBench Discussion Forum: Join Here\n\n\n\n\nThe leaderboard will be updated regularly with the latest submissions.",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#registration-setup",
    "href": "challenge/participate.html#registration-setup",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Go to the CodeBench Challenge Page.\nClick ‚ÄúJoin Challenge‚Äù.\nSign in using GitHub, Google, or your institutional email.\nAccept the data license agreement before accessing the dataset.\nYou‚Äôre ready to start! üöÄ",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#download-the-dataset",
    "href": "challenge/participate.html#download-the-dataset",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Once registered, you can:\n\nDownload the dataset directly from CodeBench.\nOr visit the Dataset Page for detailed information and visualizations.\n\nDataset Highlights:\n\nRGB + Sentinel-2 multi-spectral imagery.\nHigh-resolution ArcticDEM elevation data.\nCOCO-style instance segmentation annotations.",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#data-format",
    "href": "challenge/participate.html#data-format",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "The dataset is organized into train and test splits with COCO-style annotations:\ndataset/\n‚îú‚îÄ‚îÄ train/\n‚îÇ   ‚îú‚îÄ‚îÄ images/              # Multi-band GeoTIFFs\n‚îÇ   ‚îú‚îÄ‚îÄ masks/               # Per-instance RTS masks\n‚îÇ   ‚îî‚îÄ‚îÄ annotations.json     # COCO-style labels\n‚îî‚îÄ‚îÄ test/\n    ‚îú‚îÄ‚îÄ images/\n    ‚îî‚îÄ‚îÄ sample_submission.json\n\n\n\nItem\nFormat\nDescription\n\n\n\n\nImagery\n.tif\nMulti-band satellite imagery\n\n\nAnnotations\n.json\nCOCO-style instance segmentation\n\n\nMasks\n.png\nPer-instance RTS masks",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#baseline-notebook-starter-kit",
    "href": "challenge/participate.html#baseline-notebook-starter-kit",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "We provide a baseline notebook to help you get started quickly.\nStarter Kit Includes:\n\nData loading & visualization examples.\nBaseline multimodal GeoAI model from Li et al. (2025).\nSample inference code.\nExample submission formatting.",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#task-description",
    "href": "challenge/participate.html#task-description",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Your task is to predict per-instance RTS masks using satellite imagery and topographic data.\n\n\n\n\n\n\n\nInput\nOutput\n\n\n\n\nMulti-band satellite imagery (.tif)\nRTS instance segmentation masks",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#evaluation-metrics",
    "href": "challenge/participate.html#evaluation-metrics",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Submissions are ranked on CodeBench using the following metrics:\n\n\n\n\n\n\n\n\n\nMetric\nDefinition\nRange\nHigher = Better?\n\n\n\n\nmAP\nMean Average Precision over IoU thresholds\n0‚Äì1\n‚úÖ\n\n\nmAP50\nMean Average Precision over IoU thresholds at 0.5\n0‚Äì1\n‚úÖ\n\n\nmAP75\nMean Average Precision over IoU thresholds at 0.75\n0‚Äì1\n‚úÖ\n\n\nmAP-small\nMean Average Precision over IoU thresholds at 0.5 for small objects\n0‚Äì1\n‚úÖ\n\n\nmAP-medium\nMean Average Precision over IoU thresholds at 0.5 for medium objects\n0‚Äì1\n‚úÖ\n\n\nmAP-large\nMean Average Precision over IoU thresholds at 0.5 for large objects\n0‚Äì1\n‚úÖ\n\n\n\n\nPrimary ranking is based on mAP.",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#results-format-submission-format",
    "href": "challenge/participate.html#results-format-submission-format",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Your submission must follow the CodeBench COCO-style JSON format.\nSubmission Folder Structure:\nsubmission/\n‚îú‚îÄ‚îÄ predictions/\n‚îÇ   ‚îú‚îÄ‚îÄ image_001.json\n‚îÇ   ‚îú‚îÄ‚îÄ image_002.json\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ submission.json\nExample submission.json:\n[\n  {\n    \"image_id\": \"image_001\",\n    \"category_id\": 1,\n    \"segmentation\": [ ... ],\n    \"score\": 0.93\n  },\n  {\n    \"image_id\": \"image_002\",\n    \"category_id\": 1,\n    \"segmentation\": [ ... ],\n    \"score\": 0.87\n  }\n]\n\n‚ö†Ô∏è Important: Submissions that do not follow this format will be automatically rejected.",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#submission-instructions",
    "href": "challenge/participate.html#submission-instructions",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Train your model locally.\nGenerate predictions for the test set.\nPackage predictions in the required submission format.\nCompress into a .zip file.\nUpload to CodeBench Submissions.\nCheck your score on the leaderboard.",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#challenge-phases",
    "href": "challenge/participate.html#challenge-phases",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "The competition consists of two phases:\n\n\n\n\n\n\n\n\n\nPhase\nTimeline\nDescription\nAwards\n\n\n\n\nChallenge Phase\nSep 09 ‚Üí Nov 30, 2025\nCompete with others, submit predictions, improve models\nüèÖ Yes\n\n\nBenchmark Phase\nStarts Dec 01, 2025\nEvaluate models freely, test reproducibility, no awards\n‚ùå No\n\n\n\n\nChallenge Phase ‚Üí Compete for prizes and leaderboard positions.\nBenchmark Phase ‚Üí Keep testing your models after the official challenge ends.",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#important-dates",
    "href": "challenge/participate.html#important-dates",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Event\nDate\n\n\n\n\nCompetition Opens\nSep 09, 2025\n\n\nDataset Released\nSep 09, 2025\n\n\nFinal Submission\nNov 30, 2025\n\n\nWinners Announced\nDec 15, 2025\n\n\nBenchmark Phase Starts\nDec 01, 2025",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#qualification-rules-and-awards",
    "href": "challenge/participate.html#qualification-rules-and-awards",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "The competition is open to everyone, including students, academics, and industry professionals. We encourage participants from diverse backgrounds in computer science, remote sensing, geoscience, and related fields to form teams and compete.\n\n\n\n\nEach team can consist of 1 to 5 members.\nEach team is limited to 2 submissions per day and 100 submissions in .\nThe use of external data is permitted. Please see the Codabench page for specifics.\nCode for the top-performing models must be submitted for verification to be eligible for awards.\nFor a complete list of rules, please visit the competition page on Codabench.\n\n\n\n\nPrizes will be awarded to the top-performing teams based on the final leaderboard standings.\n\n1st Place: 1,000 USD\n2nd Place: 500 USD\n3rd Place: 200 USD",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#support-discussion",
    "href": "challenge/participate.html#support-discussion",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "CodeBench Discussion Forum: Join Here",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/participate.html#leaderboard",
    "href": "challenge/participate.html#leaderboard",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "The leaderboard will be updated regularly with the latest submissions.",
    "crumbs": [
      "Participate"
    ]
  },
  {
    "objectID": "challenge/dataset.html",
    "href": "challenge/dataset.html",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "The GeoAI Arctic Mapping Challenge dataset builds upon Yang et al. (2023) and focuses on detecting and mapping retrogressive thaw slumps (RTS)‚Äîlandscape disturbances caused by permafrost thaw. For this competition, we extend and reformat the dataset into an instance segmentation benchmark, enabling participants to train models that can better delineate individual RTS features across diverse Arctic regions.\n\nWhy it matters: RTS are sensitive indicators of permafrost thaw, which releases greenhouse gases and alters Arctic landscapes. By leveraging AI, we aim to accelerate RTS detection and improve understanding of climate-driven change.\n\n\n\nThe dataset spans 7 Arctic subregions, including:\n\nCanada: Herschel Island, Horton Delta, Tuktoyaktuk peninsulas, Banks Island\nRussia: Yamal and Gydan peninsulas, Lena River, Kolguev Island\n\n\nFigure 1. Spatial coverage of the GeoAI Arctic RTS dataset. The dataset includes 7 Arctic subregions across Canada and Russia, representing diverse geomorphic and climatic conditions (Li et al., 2025).\n\n\n\nThis dataset integrates multi-source satellite and geospatial data:\n\n\n\n\n\n\n\n\n\n\nData Type\nSource\nResolution\nBand Names\nPurpose in Task\n\n\n\n\nRGB Imagery\nMaxar\n4 m\nmaxarR, maxarG, maxarB\nHigh-resolution base imagery for visual recognition\n\n\nMulti-spectral\nSentinel-2\n10 m\nNDVI, NDWI, NIR\nVegetation & water indices for spectral feature learning\n\n\nElevation\nArcticDEM\n2 m\nrelative elevation, shaded relief\nTopographic context to improve RTS boundary detection\n\n\n\n\n\n\nOriginally, Yang et al. (2023) provided semantic segmentation masks - binary labels indicating RTS vs.¬†non-RTS regions.\nFor this challenge, we converted the dataset into instance segmentation format so each RTS feature is labeled individually.\n\n\n\n\n\n\n\n\nSatellite Image (RGB)\nSemantic Mask (Original)\nInstance Mask (This Challenge)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2. Conversion from semantic to instance segmentation masks. Original semantic masks from Yang et al.¬†(2023) labeled RTS vs.¬†non-RTS, while the challenge dataset uses instance-level masks, enabling finer-grained evaluation and model learning.\n\n\n\n\n\n\nProperty\nDescription\n\n\n\n\nTotal Regions\n7 Arctic subregions\n\n\nTotal Images\n756 train + 138 test\n\n\nTotal RTS Instances\n2,110\n\n\nImagery Resolution\nMaxar 4 m, Sentinel-2 10 m, ArcticDEM 2 m\n\n\nSpectral Bands\nRGB + NDVI, NDWI, NIR + DEM\n\n\nTask\nInstance segmentation\n\n\nLabels\nPer-instance RTS masks\n\n\nFile Formats\n.npz images + .json COCO-style annotations\n\n\nOriginal Source\nYang et al. (2023), Remote Sensing of Environment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplore additional examples to understand data variability across regions.\n\n\n\n\n\n\n\n\nDescription\nSatellite Image (RGB)\nInstance Mask (RTS Features)\n\n\n\n\nSingle large RTS\n\n\n\n\nSingle small RTS\n\n\n\n\nMultiple RTS\n\n\n\n\nRTS near snow\n\n\n\n\n\nFigure 3. Examples of RGB imagery with RTS instance annotations. Visualizing the dataset‚Äôs variability across scales and landscapes.",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "challenge/dataset.html#geographic-coverage-study-sites",
    "href": "challenge/dataset.html#geographic-coverage-study-sites",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "The dataset spans 7 Arctic subregions, including:\n\nCanada: Herschel Island, Horton Delta, Tuktoyaktuk peninsulas, Banks Island\nRussia: Yamal and Gydan peninsulas, Lena River, Kolguev Island\n\n\nFigure 1. Spatial coverage of the GeoAI Arctic RTS dataset. The dataset includes 7 Arctic subregions across Canada and Russia, representing diverse geomorphic and climatic conditions (Li et al., 2025).",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "challenge/dataset.html#data-sources-multimodal-inputs",
    "href": "challenge/dataset.html#data-sources-multimodal-inputs",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "This dataset integrates multi-source satellite and geospatial data:\n\n\n\n\n\n\n\n\n\n\nData Type\nSource\nResolution\nBand Names\nPurpose in Task\n\n\n\n\nRGB Imagery\nMaxar\n4 m\nmaxarR, maxarG, maxarB\nHigh-resolution base imagery for visual recognition\n\n\nMulti-spectral\nSentinel-2\n10 m\nNDVI, NDWI, NIR\nVegetation & water indices for spectral feature learning\n\n\nElevation\nArcticDEM\n2 m\nrelative elevation, shaded relief\nTopographic context to improve RTS boundary detection",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "challenge/dataset.html#annotation-strategy-task-setup",
    "href": "challenge/dataset.html#annotation-strategy-task-setup",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Originally, Yang et al. (2023) provided semantic segmentation masks - binary labels indicating RTS vs.¬†non-RTS regions.\nFor this challenge, we converted the dataset into instance segmentation format so each RTS feature is labeled individually.\n\n\n\n\n\n\n\n\nSatellite Image (RGB)\nSemantic Mask (Original)\nInstance Mask (This Challenge)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2. Conversion from semantic to instance segmentation masks. Original semantic masks from Yang et al.¬†(2023) labeled RTS vs.¬†non-RTS, while the challenge dataset uses instance-level masks, enabling finer-grained evaluation and model learning.",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "challenge/dataset.html#key-dataset-statistics",
    "href": "challenge/dataset.html#key-dataset-statistics",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Property\nDescription\n\n\n\n\nTotal Regions\n7 Arctic subregions\n\n\nTotal Images\n756 train + 138 test\n\n\nTotal RTS Instances\n2,110\n\n\nImagery Resolution\nMaxar 4 m, Sentinel-2 10 m, ArcticDEM 2 m\n\n\nSpectral Bands\nRGB + NDVI, NDWI, NIR + DEM\n\n\nTask\nInstance segmentation\n\n\nLabels\nPer-instance RTS masks\n\n\nFile Formats\n.npz images + .json COCO-style annotations\n\n\nOriginal Source\nYang et al. (2023), Remote Sensing of Environment",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "challenge/dataset.html#sample-visualizations",
    "href": "challenge/dataset.html#sample-visualizations",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Explore additional examples to understand data variability across regions.\n\n\n\n\n\n\n\n\nDescription\nSatellite Image (RGB)\nInstance Mask (RTS Features)\n\n\n\n\nSingle large RTS\n\n\n\n\nSingle small RTS\n\n\n\n\nMultiple RTS\n\n\n\n\nRTS near snow\n\n\n\n\n\nFigure 3. Examples of RGB imagery with RTS instance annotations. Visualizing the dataset‚Äôs variability across scales and landscapes.",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "cfp2025.html",
    "href": "cfp2025.html",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "Artificial intelligence (AI) and machine learning (ML) play an increasingly crucial role in Earth science teaching and research by accelerating large data analyses, data interpretation, enhancing predictive models, and making complex environmental processes more accessible to students and researchers alike. The first NSF Cyber2A workshop, held in October 2024, was designed to provide Arctic researchers who have a limited background in computer science and computing with the tools and knowledge of AI and ML.\nThe 2025 workshop will bring together AI and ML practitioners, instructors, and other experts to collaboratively improve and expand upon this curriculum while designing an extensible framework for delivering training in different course formats. The expected outcome of the workshop is a modular set of instructional materials and supporting guidance that educators can use to teach useful AI/ML techniques to environmental and geosciences researchers, and that self-motivated learners can use themselves to develop useful skills directly. While the instructional examples will focus on Arctic research contexts, we invite applications from individuals across a range of disciplines, professional backgrounds, and career stages who are actively engaged in the application of AI and ML in their teaching.\n\n\nThis workshop is ideal for:\n\nFaculty who are interested in offering AI-related courses centered on geoscience at their own institutions\nTrainers who are interested in adopting and enhancing our course materials to provide AI training in their training programs\nApplicants who have a solid foundation in Programming (Python, R, or similar) and AI & ML techniques\n\n\n\n\nParticipants will:\n\nReview foundational and advanced AI/ML applications relevant to geoscience research (e.g., feature detection using computer vision models, text analysis using large language models)\nDevelop pedagogical strategies for teaching AI/ML techniques to interdisciplinary research teams and students\nPromote open science practices and ethical AI use\nFoster a network of trained educators who can continue to build capacity within their institutions and regions\nCollaborate on reviewing, designing, and creating reusable AI/ML training content\n\n\n\n\nWe will delve into:\n\nPrinciples and practices for preparing AI-ready training data\nAI model building fundamentals\nAI workflow validation, verification, and troubleshooting\nAI model deployment for on-demand or batch prediction\nBest practices in using tools and platforms such as Pytorch, MLOps, Tensorboard, and Tensorflow\n\nCheck out the curriculum from our 2024 workshop at https://cyber2a.github.io/cyber2a-course/.\n\n\n\nThis is a highly collaborative and discussion-driven workshop. Expect a mix of presentations, small group activities, hands-on coding, and full room discussions.\n\n\n\n\nDates: October 20-24, 2025\nLocation: In-person at The National Center for Ecological Analysis and Synthesis (NCEAS) in Santa Barbara, CA\nCost: Support is provided by the Cyber2A award from NSF and we have limited funds to support travel and accommodations for onsite courses.\n\n\n\n\n\nI found the Cyber2A workshop to be very helpful and particularly relevant to my research. Currently, I am exploring the capability of using Deep Learning U-net models to incorporate information about atmospheric NOx from satellites, reanalysis, and surface measurements to make predictions that could inform air quality forecasts. Our hope is to investigate whether machine learning could offer a less computationally expensive option for such forecasts at high resolutions.\n- Mikhail Schee, Postdoctoral Fellow at the University of Toronto\n\n\n\nSince attending, I‚Äôve been developing a KMeans-based method to classify glacier surface conditions using Sentinel-2 imagery. This unsupervised approach has helped me label snow, ice, and land areas, which I then use to train supervised machine learning classifiers to estimate snow cover ratios and snowline altitudes across the Canadian Arctic.\n- Wai-Yin Cheung\nProject Showcase: Click an image to enlarge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReady to apply? Submit your application here.\nApplication Deadline: July 14, 2025\nPlease contact greco@nceas.ucsb.edu with any questions.\n\n\n\nASU, NCEAS at UCSB, Woodwell Climate Center, UIUC, and NCSA\n\n\n\nNational Science Foundation under awards 2230034 and 2230035."
  },
  {
    "objectID": "cfp2025.html#who-should-attend",
    "href": "cfp2025.html#who-should-attend",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "This workshop is ideal for:\n\nFaculty who are interested in offering AI-related courses centered on geoscience at their own institutions\nTrainers who are interested in adopting and enhancing our course materials to provide AI training in their training programs\nApplicants who have a solid foundation in Programming (Python, R, or similar) and AI & ML techniques"
  },
  {
    "objectID": "cfp2025.html#workshop-objectives",
    "href": "cfp2025.html#workshop-objectives",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "Participants will:\n\nReview foundational and advanced AI/ML applications relevant to geoscience research (e.g., feature detection using computer vision models, text analysis using large language models)\nDevelop pedagogical strategies for teaching AI/ML techniques to interdisciplinary research teams and students\nPromote open science practices and ethical AI use\nFoster a network of trained educators who can continue to build capacity within their institutions and regions\nCollaborate on reviewing, designing, and creating reusable AI/ML training content"
  },
  {
    "objectID": "cfp2025.html#ai-ml-tools-techniques-covered",
    "href": "cfp2025.html#ai-ml-tools-techniques-covered",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "We will delve into:\n\nPrinciples and practices for preparing AI-ready training data\nAI model building fundamentals\nAI workflow validation, verification, and troubleshooting\nAI model deployment for on-demand or batch prediction\nBest practices in using tools and platforms such as Pytorch, MLOps, Tensorboard, and Tensorflow\n\nCheck out the curriculum from our 2024 workshop at https://cyber2a.github.io/cyber2a-course/."
  },
  {
    "objectID": "cfp2025.html#format",
    "href": "cfp2025.html#format",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "This is a highly collaborative and discussion-driven workshop. Expect a mix of presentations, small group activities, hands-on coding, and full room discussions."
  },
  {
    "objectID": "cfp2025.html#key-information",
    "href": "cfp2025.html#key-information",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "Dates: October 20-24, 2025\nLocation: In-person at The National Center for Ecological Analysis and Synthesis (NCEAS) in Santa Barbara, CA\nCost: Support is provided by the Cyber2A award from NSF and we have limited funds to support travel and accommodations for onsite courses."
  },
  {
    "objectID": "cfp2025.html#hear-from-our-alumni",
    "href": "cfp2025.html#hear-from-our-alumni",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "I found the Cyber2A workshop to be very helpful and particularly relevant to my research. Currently, I am exploring the capability of using Deep Learning U-net models to incorporate information about atmospheric NOx from satellites, reanalysis, and surface measurements to make predictions that could inform air quality forecasts. Our hope is to investigate whether machine learning could offer a less computationally expensive option for such forecasts at high resolutions.\n- Mikhail Schee, Postdoctoral Fellow at the University of Toronto\n\n\n\nSince attending, I‚Äôve been developing a KMeans-based method to classify glacier surface conditions using Sentinel-2 imagery. This unsupervised approach has helped me label snow, ice, and land areas, which I then use to train supervised machine learning classifiers to estimate snow cover ratios and snowline altitudes across the Canadian Arctic.\n- Wai-Yin Cheung\nProject Showcase: Click an image to enlarge"
  },
  {
    "objectID": "cfp2025.html#application",
    "href": "cfp2025.html#application",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "Ready to apply? Submit your application here.\nApplication Deadline: July 14, 2025\nPlease contact greco@nceas.ucsb.edu with any questions."
  },
  {
    "objectID": "cfp2025.html#organizers",
    "href": "cfp2025.html#organizers",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "ASU, NCEAS at UCSB, Woodwell Climate Center, UIUC, and NCSA"
  },
  {
    "objectID": "cfp2025.html#sponsor",
    "href": "cfp2025.html#sponsor",
    "title": "2025 Call for Participation",
    "section": "",
    "text": "National Science Foundation under awards 2230034 and 2230035."
  },
  {
    "objectID": "challenge/index.html",
    "href": "challenge/index.html",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Welcome to the GeoAI Arctic Mapping Challenge, a competition at the intersection of Geoscience and Artificial Intelligence. We invite you to develop innovative AI models to map retrogressive thaw slumps (RTS), a critical indicator of climate change in the Arctic.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/index.html#newspaper-news",
    "href": "challenge/index.html#newspaper-news",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "newspaper News",
    "text": "newspaper News\n\n(09/09/25) Competition Kick-off! We are excited to announce the official launch of the GeoAI Arctic Mapping Challenge.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/index.html#landscape_2-what-is-retrogressive-thaw-slumps-rts",
    "href": "challenge/index.html#landscape_2-what-is-retrogressive-thaw-slumps-rts",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "landscape_2 What is Retrogressive Thaw Slumps (RTS)?",
    "text": "landscape_2 What is Retrogressive Thaw Slumps (RTS)?\n\n\n\nCredit: Woodwell Climate Research Center\n\n\nRetrogressive thaw slumps (RTS) are dramatic forms of permafrost degradation that occur when ice-rich ground thaws and collapses, often triggered by warming temperatures or surface disturbances. The image above shows a classic example: a headwall of exposed ice retreating upslope, releasing sediment, water, and organic carbon into surrounding landscapes and rivers. These slumps can rapidly expand over time, reshaping terrain and contributing to greenhouse gas emissions as long-frozen carbon is mobilized. For more details on the processes, impacts, and recent advances in detecting RTS using machine learning and satellite imagery, see this article from Woodwell Climate Research Center.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/index.html#info-about-the-challenge",
    "href": "challenge/index.html#info-about-the-challenge",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "info About the Challenge",
    "text": "info About the Challenge\nRetrogressive thaw slumps (RTS) are landslides that occur in icy permafrost terrain. As the climate warms, these slumps are becoming more frequent and are dramatically reshaping the Arctic landscape. They have significant environmental impacts, including altering hydrology, affecting ecosystems, and accelerating the release of greenhouse gases.\nMapping RTS is challenging due to their small size, subtle appearance, and dynamic evolution over time. This competition invites you to leverage deep learning and GeoAI to automatically detect and map these features. By participating, you will contribute to advancing permafrost science and improving our understanding of Arctic change.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/index.html#handshake-collaborators",
    "href": "challenge/index.html#handshake-collaborators",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "handshake Collaborators",
    "text": "handshake Collaborators\n\nWenwen Li, Arizona State University\nAnna Liljedahl, Woodwell Climate Research Center\nMatthew Jones, National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara\nKenton McHenry, National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign\nYili Yang, Woodwell Climate Research Center\nBrendan Rogers, Woodwell Climate Research Center\nChia-Yu Hsu, Arizona State University",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/index.html#groups-partners",
    "href": "challenge/index.html#groups-partners",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "groups Partners",
    "text": "groups Partners",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/index.html#paid-sponsors",
    "href": "challenge/index.html#paid-sponsors",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "paid Sponsors",
    "text": "paid Sponsors",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/index.html#library_books-references",
    "href": "challenge/index.html#library_books-references",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "library_books References",
    "text": "library_books References\nThe GeoAI Arctic Mapping Challenge builds upon a RTS dataset and cutting-edge multimodal GeoAI models. We encourage participants to cite the following works when using the dataset or baseline model:\n\nDataset Source\nThe dataset was curated by Yang et al. (2023), who developed a deep learning approach for mapping RTS from satellite imagery. This dataset forms the foundation of the competition.\n\nYang, Yili, Brendan M. Rogers, Greg Fiske, Jennifer Watts, Stefano Potter, Tiffany Windholz, Andrew Mullen, Ingmar Nitze, and Susan M. Natali. ‚ÄúMapping retrogressive thaw slumps using deep neural networks.‚Äù Remote Sensing of Environment 288 (2023): 113495. https://doi.org/10.1016/j.rse.2023.113495\n\n@article{yang2023mapping,\n  title={Mapping retrogressive thaw slumps using deep neural networks},\n  author={Yang, Yili and Rogers, Brendan M and Fiske, Greg and Watts, Jennifer and Potter, Stefano and Windholz, Tiffany and Mullen, Andrew and Nitze, Ingmar and Natali, Susan M},\n  journal={Remote Sensing of Environment},\n  volume={288},\n  pages={113495},\n  year={2023},\n  publisher={Elsevier}\n}\n\n\nOur Multimodal GeoAI Model\nWe provide a sample notebook using the baseline model from Li et al. (2025), a multi-scale vision transformer-based multimodal GeoAI model that integrates multi-spectral imagery and topographic features for high-accuracy RTS mapping in Arctic permafrost regions.\n\nLi, Wenwen, Chia-Yu Hsu, Sizhe Wang, Zhining Gu, Yili Yang, Brendan M. Rogers, and Anna Liljedahl. ‚ÄúA multi-scale vision transformer-based multimodal GeoAI model for mapping Arctic permafrost thaw.‚Äù IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (2025). https://doi.org/10.1109/JSTARS.2025.3564310\n\n@article{li2025multi,\n  title={A multi-scale vision transformer-based multimodal GeoAI model for mapping Arctic permafrost thaw},\n  author={Li, Wenwen and Hsu, Chia-Yu and Wang, Sizhe and Gu, Zhining and Yang, Yili and Rogers, Brendan M and Liljedahl, Anna},\n  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},\n  year={2025},\n  publisher={IEEE}\n}",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/index.html#image-dataset-samples",
    "href": "challenge/index.html#image-dataset-samples",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "image Dataset Samples",
    "text": "image Dataset Samples\nThe dataset consists of high-resolution, multi-spectral satellite imagery paired with segmentation masks outlining RTS boundaries. While the dataset provides multi-band inputs (including non-visible spectral channels), the sample images below are displayed using RGB composites for visualization purposes only.\n\n\n\nInput: RGB composite example\nTarget: RTS segmentation",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "challenge/people.html",
    "href": "challenge/people.html",
    "title": "GeoAI Arctic Mapping Challenge",
    "section": "",
    "text": "Collaborators"
  },
  {
    "objectID": "news/content/050123_geo_ai_martian_challenge.html",
    "href": "news/content/050123_geo_ai_martian_challenge.html",
    "title": "Winners announced for the 1st GeoAI Martian Challenge!",
    "section": "",
    "text": "The 2022 GeoAI Martian Challenge is the very first in the series of GeoAI challenges hosted by the Cyberinfrastructure and Computational Intelligence Lab (CICI) and the Spatial Analysis Research Center (SPARC) of Arizona State University (ASU). This is a collaboration among researchers from multiple disciplines, organizations and sectors, including ASU, U.S. Geological Survey (USGS), Jet Propulsion Laboratory (JPL), Oak Ridge National Lab, Esri, Google and American Geographical Society. The goal of this object detection challenge is to broaden the participation of, but not limited to, students and early career scholars in geospatial sciences, computer science, Earth and space sciences, data science, and fields relevant to this exciting research community. Through this challenge, we also hope to form a strong research network to facilitate collaboration among researchers and practitioners from different disciplines to jointly promote cutting-edge GeoAI research and education, as well as their translational solutions to problems in a wide range of environmental and social science domains."
  },
  {
    "objectID": "news/content/060225_2025_workshop.html",
    "href": "news/content/060225_2025_workshop.html",
    "title": "Announcing the 2025 Workshop: Scaling Impact in AI/ML Education for Arctic Research",
    "section": "",
    "text": "We are excited to announce the upcoming second ‚ÄúScaling Impact: Co-Creating a Shared Framework for Teaching AI and Machine Learning with Applications in Arctic Research‚Äù workshop, to be held from October 20-24, 2025, in beautiful Santa Barbara, CA!\nBuilding on the success of our 2024 workshop, this highly collaborative event will bring together AI/ML practitioners, dedicated instructors, and subject matter experts. Our collective goal is to enhance and expand the existing curriculum for teaching AI/ML in Earth sciences, with a special focus on Arctic research applications. Participants will play a key role in designing an extensible framework to support AI/ML training across various course formats and learning environments.\nThis workshop is a unique opportunity for faculty, trainers, and researchers with an interest in AI/ML teaching in geosciences to:\n\nCollaboratively review, design, and create reusable AI/ML training content.\nDevelop new pedagogical strategies for interdisciplinary teams.\nFoster a network of educators to build AI/ML capacity in geosciences.\n\nKey Details:\n\nWorkshop Dates: October 20-24, 2025\nLocation: The National Center for Ecological Analysis and Synthesis (NCEAS), Santa Barbara, CA\nApplication Deadline: July 14, 2025\n\nTravel and accommodation support is available for a limited number of participants, thanks to funding from the National Science Foundation.\nInterested in shaping the future of AI/ML education in Earth sciences?\nWe invite you to learn more about the workshop objectives, who should attend, and how to apply by visiting our full Call for Participation.\nWe look forward to your applications and another impactful workshop!"
  },
  {
    "objectID": "news/content/081023_multi_institution_project.html",
    "href": "news/content/081023_multi_institution_project.html",
    "title": "The multi-institution project received $5M in funding from Google.org to better understand Arctic permafrost thaw",
    "section": "",
    "text": "Photo courtesy Unsplash\n\n\nAs the Arctic warms at nearly four times the global rate, permafrost ‚Äì frozen ground that has remained below 0 degrees Celsius for at least two consecutive years ‚Äì is thawing rapidly, causing widespread ground collapse and infrastructure damage, threatening Arctic communities and releasing carbon into the atmosphere.\nTo date, while vast amounts of high spatial and temporal resolution data has been collected, real-time analysis of permafrost thaw has been limited, far behind the speed in which data is produced.\nNew research by Wenwen Li, professor in the School of Geographical Sciences and Urban Planning at Arizona State University, aims to support the development of a new, open-access resource that will use satellite data and artificial intelligence technology to make it possible to track Arctic permafrost thaw in near real time.\nThe project, led by the Woodwell Climate Research Center and funded by a $5 million grant from Google.org, will use AI technology to streamline the data analysis process and make it easier to rapidly identify patterns and trends in permafrost thaw datasets that will be essential to informing climate mitigation and adaptation strategies.\n‚ÄúThis is an exciting era of AI and geospatial sciences,‚Äù said Li, whose research uses AI to explore new questions about the geographic world. ‚ÄúLeveraging them to understand the ever-changing Earth‚Äôs environment and its climate ‚Äî such as Arctic warming, excessive heatwaves and increasingly occurring disasters ‚Äî offers a real chance for us as a society to better combat climate change, mitigate its impacts and plan for a more sustainable and resilient future.‚Äù\nThe three-year effort ‚Äî an expansion of the Permafrost Discovery Gateway ‚Äî will focus on building automated workflows for geospatial product creation, AI models capable of identifying changes, patterns and trends, and environmental and climatic drivers. It will also focus on building tera to petabyte scale permafrost thaw datasets.\n‚ÄúTimely tracking of permafrost thaw is critical to assessing impacts and informing action, but current limitations in technology, combined with the rapid pace of change in Arctic landscapes, have held us all back,‚Äù said Anna Liljedahl, Woodwell Climate associate scientist and project lead. ‚ÄúThis project will be groundbreaking in speeding up data analysis and unlocking completely new technological capabilities in how we do science in swiftly evolving landscapes, and, ultimately, what science itself can do.‚Äù\nIn particular, the technology will enable scientists, decision-makers, community members, and other interested groups and individuals to:\n‚Ä¢ Explore permafrost thaw features that formed during the previous month.\n‚Ä¢ Check out seasonal forecasts of permafrost thaw.\n‚Ä¢ Predict disturbance events based on weather forecasts.\n‚Ä¢ Estimate carbon and infrastructure loss from abrupt permafrost thaw.\n‚Ä¢ Analyze the shape and size of permafrost thaw features and their patterns across the landscape over time.\nThis resource will also be applicable beyond the scope of permafrost thaw, enabling experts to adapt this technology for other research areas and expand access to key climate data and actionable insights across a range of issues and regions of the world.\n‚ÄúIt is truly wonderful to have the opportunity to work with a multi-institutional team of experts in Arctic science, cyberinfrastructure, big data, high-performance computing, remote sensing and AI,‚Äù said Li, who also is the research director of ASU‚Äôs Spatial Analysis Research Center.\n‚ÄúUnderstanding change in the Arctic is a complex scientific problem, and we need team science to tackle this challenge,‚Äù Li said. ‚ÄúOur ASU team has collaborated with many of these partners in the past, and I look forward to working together to create exciting new science through this Google.org project.‚Äù\nThe research is being conducted in partnership with Woodwell Climate Research Center; University of Connecticut; University of California Santa Barbara; National Center for Supercomputing Applications; Arizona State University; Alfred Wegener Institute; University of Alaska, Fairbanks; and Alaska Native Tribal Health Consortium.\nMaddie Rocklin with the Woodwell Climate Research Center contributed to this article.\nTop photo courtesy Unsplash"
  },
  {
    "objectID": "news/content/103024_review_on_ai_in_arctic_sea_ice.html",
    "href": "news/content/103024_review_on_ai_in_arctic_sea_ice.html",
    "title": "New review paper on AI in Arctic Sea Ice Remote Sensing!",
    "section": "",
    "text": "As AI continues to advance climate science, a recent paper from the Cyber2A team explores its unique contributions to Arctic sea ice remote sensing. The study reviewed over 160 papers, summarizing AI applications addressing key challenges such as sea ice lead detection, thickness estimation, concentration and extent forecasting, motion detection, and type classification. The paper also discusses future research directions, highlighting how the sea ice community can further benefit from cutting-edge AI technology. Read it here: https://www.mdpi.com/2072-4292/16/20/3764\n\n\n\nAdvancing Arctic Sea Ice Remote Sensing with AI and Deep Learning: Opportunities and Challenges.\n\n\n\n\n\nAn overview of AI applications in Arctic sea ice research.\n\n\n\n\n\n\n\n\nTipReference\n\n\n\nLi, W., Hsu, C. Y., & Tedesco, M. (2024). Advancing Arctic Sea Ice Remote Sensing with AI and Deep Learning: Opportunities and Challenges. Remote Sensing, 16(20), 3764."
  },
  {
    "objectID": "people/advisory-board.html",
    "href": "people/advisory-board.html",
    "title": "Advisory Board",
    "section": "",
    "text": "Samantha T. Arundel\nUnited States Geological Survey, Rolla, MO, USA\n\n\nLingcao Huang\nPostdoctoral scholar, University of Victoria, Canada\n\n\nVera Kuklina\nResearch Professor, The George Washington University\n\n\nJianwu Wang\nAssociate Professor, University of Maryland, Baltimore County\n\n\nElizabeth A. Wentz\nVice Provost and Dean, Arizona State University\n\n\nLawrence M. Vulis\nPostdocral Scientist, Los Alamos National Laboratory"
  },
  {
    "objectID": "people/content/anna_liljedahl.html",
    "href": "people/content/anna_liljedahl.html",
    "title": "Anna Liljedahl",
    "section": "",
    "text": "I integrate field measurements, remote sensing, and computational modeling to better understand hydrology, permafrost and/or glacier interactions and the controls on the Arctic and sub-arctic hydrologic cycle."
  },
  {
    "objectID": "people/content/caleb_billmeier.html",
    "href": "people/content/caleb_billmeier.html",
    "title": "Caleb Billmeier",
    "section": "",
    "text": "Co-founder of Wellspring Group Consulting, he and Kate are the driving force behind the vision, goals, and operations of the business. Caleb worked as a consultant in rural Alaska for eight years, researching the impacts of state and federally-funded development projects on local subsistence practices and cultural resources. He has also worked as a tribal Grants Manager in his hometown of Seldovia, Alaska and as a contributor to a non-profit that seeks to educate and engage the public on Alaska‚Äôs natural resource issues.\nPrior to his work in Alaska, Caleb participated in collaborative research programs at the Kathmandu Valley Preservation Trust (KVPT) in Patan, Nepal. He also helped develop a community-based model for heritage tourism in the Indian state of Uttarakhand while working at the Indian National Trust for Art and Cultural Heritage (INTACH) in Delhi, India. He received his M.A.¬†in Cross-Cultural Studies from the University of Alaska Fairbanks in 2009, following a B.A. in Historic Preservation from the University of Mary Washington in 2004.\nCaleb and Kate spent nearly a decade as a commercial fishing family in Bristol Bay, and continue to live and work in rural Alaska. He lives with his wife and two kids in Seldovia, Alaska."
  },
  {
    "objectID": "people/content/chandi_witharana.html",
    "href": "people/content/chandi_witharana.html",
    "title": "Chandi Witharana",
    "section": "",
    "text": "My research efforts broadly capture the methodological developments and adaptations to unseal faster, deeper, and more accurate analysis of large volumes of high-resolution remote sensing data. Object-based image analysis, point cloud analytics, machine learning, unmanned aerial systems (UAS) stand out as some of the key pitches in my agenda. I conduct interdisciplinary remote sensing research with high international visibility, speaking equally to the transformational uses of remote sensing in environmental, industrial, agricultural, and humanitarian applications. My scope is global. Diversity is an integral part of myself, as well as my research. Some of my work includes mapping ice-wedge polygonal Arctic tundra from sub-meter satellite imagery, on-demand censusing of Antarctic wildlife from space, 3D infrastructure analytics for electric utility industry, unmanned aerial spectroscopy for integrated pest management applications, and on-demand censusing of refugees in armed-conflicted areas in South Asia. Thinking beyond its research and industrial merits, I always value the strengths of remote sensing to address the requirements of the Next Generation Science Standards via the key elements from physics and engineering. I am actively seeking creative ways, such as imagery-enabled lesson plans to harness remote sensing in K-12 STEM education."
  },
  {
    "objectID": "people/content/jim_regetz.html",
    "href": "people/content/jim_regetz.html",
    "title": "Jim Regetz",
    "section": "",
    "text": "At NCEAS, I lead an environmental data science program focused on enabling individual researchers and teams to achieve more impactful outcomes through better analysis, modeling, visualization, and data management. With a career arc traversing both academia and the commercial software industry, I‚Äôve delivered data-driven insights and helped build new data/analytics infrastructure across diverse application domains, and am especially passionate about expanding data science literacy and expertise in the practitioner community."
  },
  {
    "objectID": "people/content/kenton_mchenry.html",
    "href": "people/content/kenton_mchenry.html",
    "title": "Kenton McHenry",
    "section": "",
    "text": "I apply my experience in Computer Vision and Artificial Intelligence towards research and development in cyberinfrastructure for digital preservation, auto-curation, and providing access to contents in large unstructured digital collections (e.g.¬†image collections)."
  },
  {
    "objectID": "people/content/matthew_jones.html",
    "href": "people/content/matthew_jones.html",
    "title": "Matthew Jones",
    "section": "",
    "text": "My research focuses on environmental informatics, and particularly software for management, integration, analysis, and modeling of heterogeneous environmental data. Recent projects have produced effective new techniques for information management and analysis, including metadata standards, data management software, and data analysis software such as scientific workflow systems"
  },
  {
    "objectID": "people/content/sandeep_puthanveetil_satheesan.html",
    "href": "people/content/sandeep_puthanveetil_satheesan.html",
    "title": "Sandeep Puthanveetil Satheesan",
    "section": "",
    "text": "I am a Senior Research Software Engineer at NCSA. My educational background and experience are in Computer Science and Applied Computer Vision. I collaborate with faculty, researchers, students, industry partners, and other fellow research software engineers to design and develop software to support research. I have previously worked on research projects spanning the areas of biometrics, face recognition, image and video analytics, unstructured data curation, digital humanities, research data management, agriculture, policy design, and palynology. My research interests are in computer vision, artificial intelligence, research data analysis and management, and research software engineering."
  },
  {
    "objectID": "people/content/wenwen_li.html",
    "href": "people/content/wenwen_li.html",
    "title": "Wenwen Li",
    "section": "",
    "text": "I am a geospatial information scientist specializing in cyberinfrastructure, AI, and big data analytics and their applications in environmental studies, especially Arctic science."
  },
  {
    "objectID": "people/content/yili_yang.html",
    "href": "people/content/yili_yang.html",
    "title": "Yili Yang",
    "section": "",
    "text": "Dr.¬†Yili Yang‚Äôs passion for earth sciences and data science stems from a deep motivation to address the pressing challenges our planet faces today. With a background in geology and petrophysics, Dr.¬†Yang possesses a strong foundation in understanding the intricacies of the Earth‚Äôs systems. However, recognizing the transformative potential of data science, he has shifted his focus towards utilizing state-of-the-art technologies such as deep learning and computer vision (image processing) to tackle earth science challenges.\nDr.¬†Yang‚Äôs expertise lies in satellite image processing, object detection, and semantic segmentation, which he believes can empower traditional earth sciences with the power of AI. By leveraging advanced data science techniques, he aims to unlock new insights and enhance our understanding of complex environmental processes.\nCurrently, Dr.¬†Yang is engaged in a critical project that involves using deep neural networks to map retrogressive thaw slumps in northern Siberia. This research is vital in modeling carbon emissions resulting from permafrost thaw, contributing to a comprehensive understanding of the impact of climate change. Additionally, he actively participates in other projects that harness the potential of machine learning, such as mapping small water bodies, mapping wildfires, and modeling carbon fluxes in the Arctic.\nDr.¬†Yang‚Äôs interdisciplinary approach, combining his background in earth sciences with the power of data science, allows him to bridge the gap between traditional methodologies and cutting-edge technologies. By embracing this convergence, he aims to address the complex environmental challenges we face today more effectively."
  },
  {
    "objectID": "people/project-collaborators.html",
    "href": "people/project-collaborators.html",
    "title": "Project Collaborators",
    "section": "",
    "text": "Roman Dial\nProfessor, Alaska Pacific University\n\n\nAaron Dotson\nVice Chancellor for Research, University of Alaska Anchorage\n\n\nHoward Epstein\nProfessor, University of Virginia\n\n\nTrudi Hoogenboom\nAstra Nova School\n\n\nShishay T. Kidanu\nAssistant Professor, University of Alaska Fairbanks\n\n\nDmitry (Dima) Streletskiy\nAssociate Professor, The George Washington University\n\n\nCriag E. Tweedie\nProfessor, University of Texas at El Paso"
  },
  {
    "objectID": "webinars/content/040725-infrastructure-mapping-with-AI.html",
    "href": "webinars/content/040725-infrastructure-mapping-with-AI.html",
    "title": "Infrastructure Mapping with AI",
    "section": "",
    "text": "Abstract\nArtificial Intelligence for mapping Arctic infrastructures on April 7, 9 am AKT/ 1 pm ET was co-hosted by NSF Cyber2A project, the CRAFT Research Coordination Network (Co-creating Research for Just Arctic Future Infrastructure Transformations, Resilience, and Adaptation), and the Permafrost Discovery Gateway project. The Webinar‚Äôs host: Wenwen Li (School of Geographical Sciences and Urban Planning, Arizona State University). Panelists: Chandi Witharana (Assistant Professor of Remote Sensing in the Department of Natural Resources and the Environment at the University of Connecticut), Elias Manos (PhD student at the University of Connecticut Department of Natural Resources & the Environment), and Bessie Weston (Indigenous Alaska Native of Cup‚Äôig decent, Co-PI and Mekoryuk Advisory Board Member for the NSF NNA Project, Meq Unguvatarkarput).\n\n\nDate and Time\nApril 7, 2025, 9:00 - 10:00 AM AKT/ 1:00 - 2:00 PM ET\n\n\nSpeaker Biography\n\n\n\n\n\n\nBessie Lea Weston is an Indigenous Alaska Native of Cup‚Äôig decent and was raised in the Bering Sea on Nunivak Island. Bessie currently serves as a Co-PI and Mekoryuk Advisory Board Member for the NSF NNA Project, Meq Unguvatarkarput. Her background includes visioning, planning, and implementing rural environmental and small scale infrastructural improvements.\n\n\n\n\n\n\n\n\n\nChandi Witharana is an Assistant Professor of Remote Sensing in the Department of Natural Resources and the Environment at the University of Connecticut. His research focuses on AI-driven methodological advancements and adaptations to enhance the efficiency and accuracy of large-scale analyses of high-resolution remote sensing data across multiple application domains.\n\n\n\n\n\n\n\n\n\nElias Manos is a geographer and PhD student at the University of Connecticut Department of Natural Resources & the Environment. He is also a team member on the Permafrost Discovery Gateway project. He is broadly interested in using earth observation for disaster risk management and monitoring human exposure to hazards. His research focuses on developing a comprehensive, publicly available, pan-Arctic geospatial data inventory of community infrastructure to further knowledge of the socioeconomic risks of permafrost thaw at multiple scales. This work leverages artificial intelligence techniques to automatically map buildings and roads from high-resolution satellite imagery of Arctic communities. Recent findings of this research indicate that estimated infrastructure damages caused by projected permafrost thaw in Alaska may cost double the amount found in previous studies\n\n\n\n\n\n\n\n\n\nWenwen Li is a professor in the School of Geographical Sciences and Urban Planning at Arizona State University. My research focuses on cyberinfrastructure, big data, and geospatial artificial intelligence and their applications in data- and computation-intensive challenges, particularly in the Arctic. My interest in Arctic research began during my PhD, when I helped build a virtual spatial data infrastructure to make Arctic data more easily shareable, accessible, and reusable across national boundaries. Since then, I have been developing cyberinfrastructure solutions, such as PolarHub and PolarGlobe, to advance our understanding of Arctic changes and their impact on ecosystems and communities.\n\n\n\n\n\nRecording"
  },
  {
    "objectID": "webinars/content/081825-semantic-enrichment-LLM-analytics-mindat-portal.html",
    "href": "webinars/content/081825-semantic-enrichment-LLM-analytics-mindat-portal.html",
    "title": "Semantic Enrichment and LLM-Driven Analytics to the Mindat Open Data Portal",
    "section": "",
    "text": "Abstract\nMindat is the world‚Äôs largest open mineral database, featuring over 6,600 mineral species and 430,000 localities. Recently, through NSF and NAIRR support, we have made enhancements to the Mindat open data service by integrating semantic technologies and large language models (LLMs) to improve data quality, usability, and accessibility. We have aligned records with community standards (e.g., rock and mineral nomenclature and classification) and persistent identifiers, which enable FAIR-compliant, machine-readable data access via a new open data API. On top of this infrastructure, LLMs assist with natural-language querying, record cleansing, synonym resolution, and geospatial disambiguation. Embedding-based search and interactive visualizations, such as mineral‚Äìelement networks and locality heatmaps, allow users to explore data with minimal coding. These innovations reduce barriers to data use, enhance transparency, and support reproducible geoscience research. This work demonstrates how semantic enrichment and LLM tools can transform domain-specific data services into intelligent, user-friendly platforms for data science in the Earth sciences.\n\n\nDate and Time\nAugust 18, 2025, 10:00 - 11:00 AM PDT\n\n\nSpeaker Biography\nXiaogang (Marshall) Ma is an Associate Professor of Computer Science at the University of Idaho. He received his Ph.D.¬†degree of Earth Systems Science and GIScience from University of Twente, Netherlands in 2011, and then completed postdoctoral training of Data Science at Rensselaer Polytechnic Institute. His research focuses on deploying data science in the Semantic Web to support cross-disciplinary collaboration and scientific discovery, with broad interests in complex systems in Earth and environmental sciences, data interoperability and provenance, and visualized exploratory analysis of Big and Small Data.\n\n\nRecording"
  },
  {
    "objectID": "webinars/content/111323_geofm.html",
    "href": "webinars/content/111323_geofm.html",
    "title": "A Framework for Building and Finetuning Geospatial Foundation Models",
    "section": "",
    "text": "Foundation models are artificial intelligence (AI) models that are pre-trained on large unlabeled datasets through self-supervision and then fine-tuned for different downstream tasks. There is increasing interest in the scientific community to investigate whether this approach can be successfully applied to domains beyond natural language processing and computer vision to effectively build generalist AI models that make use of different types of data. Here, IBM and NASA present the first end-to-end framework for pre-training and fine-tuning foundation models efficiently from a large source of geospatial data. We have implemented and applied this framework to produce Prithvi, a geospatial foundation model pre-trained on multispectral satellite imagery from the NASA Harmonized Landsat-Sentinel 2 (HLS) dataset. The framework supports automated statistical smart sampling strategies based on whether, land cover and other datasets to maximize impact and minimize waste of resources (e.g.¬†avoiding areas and time ranges that would not bring any new information). Prithvi is a Temporal Vision Transformer that includes positional and temporal embeddings, which was trained on IBM Cloud Vela cluster (NVIDIA A100 GPUs) using a Masked Auto Encoder approach and Mean Squared Error loss function for a total of 10k GPUs hours. We demonstrated using the fine-tuning workflows built in our framework that Prithvi could be successfully fine-tuned to produce state-of-the-art AI models for Earth observation tasks: flood mapping, burn scar identification and multi-temporal crop classification. We carefully studied the impact of Prithvi‚Äôs pre-trained weights on the downstream tasks by comparing learning curves for 1) fine-tuning the whole model, 2) fine-tuning only the downstream task decoder, 3) training the model without taking advantage of Prithvi‚Äôs pre-trained weights. Furthermore, given the scarcity of labeled data for Earth observation tasks, we progressively decreased the amount of labeled data available for fine-tuning the model to assess data efficiency. This analysis showed that using Prithvi we could achieve peak performance on test data quicker and with less training data (i.e.¬†up to 50% less). Finally, in order to increase the impact of this work, the pre-trained model and fine-tuning workflows have been made publicly available through Hugging Face.\n\nRecording"
  },
  {
    "objectID": "webinars/past-webinars.html",
    "href": "webinars/past-webinars.html",
    "title": "Past Webinars",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nSemantic Enrichment and LLM-Driven Analytics to the Mindat Open Data Portal\n\n\n\n\n\n\n\n\nAug 18, 2025\n\n\nDr.¬†Xiaogang Ma, Associate Professor of Computer Science, University of Idaho\n\n\n\n\n\n\n\n\n\n\n\n\nInfrastructure Mapping with AI\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nBessie Lea Weston, NSF NNA Project, Meq Unguvatarkarput  Dr.¬†Chandi Witharana, University of Connecticut  Elias Manos, University of Connecticut  Dr.¬†Wenwen Li, Arizona State University\n\n\n\n\n\n\n\n\n\n\n\n\nHyper-Spatial Remote Sensing\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nDr.¬†Compton Tucker, National Aeronautics and Space Administration (NASA)\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Neural Representations of our Planet from Earth Observation Data\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nDr.¬†Konstantin Klemmer, Microsoft Research\n\n\n\n\n\n\n\n\n\n\n\n\nA Framework for Building and Finetuning Geospatial Foundation Models\n\n\n\n\n\n\n\n\nNov 13, 2023\n\n\nDr.¬†Daniela Szwarcman, IBM ResearchDr.¬†Paolo Fraccaro, IBM Research\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshop/index.html",
    "href": "workshop/index.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Welcome to our groundbreaking workshop aimed at empowering Arctic scientists with the essential tools and knowledge of Artificial Intelligence (AI). In an era where data-driven science is revolutionizing research methodologies, the Arctic region‚Äôs intricate and dynamic nature poses unique challenges and opportunities. This 5-day in-person workshop, hosted by ASU, UCSB, Woodwell, UIIC, and NCSA as part of the NSF Cyber2A training program, is specifically tailored for scientists engaged in Arctic research who may have limited backgrounds in computer science and computing but are eager to integrate AI into their research.\nOur comprehensive curriculum, developed through extensive research and training, emphasizes fundamental AI concepts, hands-on experiences, and addresses the particular challenges encountered in Arctic research. Participants will gain an overview of AI basics, including key concepts, methodologies, and the language of AI that every scientist should know. Additionally, the workshop will delve into practical AI applications, such as using AI models and tools to analyze data, predict outcomes, and gain insights into complex Arctic phenomena. Join us in this transformative journey to understand and interact with the Arctic environment through the powerful lens of AI.",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#in-this-course-participants-will-learn-to",
    "href": "workshop/index.html#in-this-course-participants-will-learn-to",
    "title": "Cyber2A Workshop",
    "section": "In this course, participants will learn to:",
    "text": "In this course, participants will learn to:\n\nUnderstand AI Fundamentals\nHands-on Experience with AI Tools\nAddress Arctic-Specific Challenges\nPromote Collaborative Learning\nFacilitate Future Research",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#who-should-attend",
    "href": "workshop/index.html#who-should-attend",
    "title": "Cyber2A Workshop",
    "section": "Who Should Attend",
    "text": "Who Should Attend\n\nArctic researchers and scientists with limited computing or AI background\nData analysts and scientists in related fields seeking to apply AI in Arctic research\nEducators and trainers looking to incorporate AI into their science curricula",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#dates",
    "href": "workshop/index.html#dates",
    "title": "Cyber2A Workshop",
    "section": "Dates",
    "text": "Dates\nWorkshop Dates: October 21st, 2024 - October 25th, 2024",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#location",
    "href": "workshop/index.html#location",
    "title": "Cyber2A Workshop",
    "section": "Location",
    "text": "Location\nVenue: In-Person at the National Center for Ecological Analysis and Synthesis (NCEAS) in Santa Barbara, California",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#registration-and-fees",
    "href": "workshop/index.html#registration-and-fees",
    "title": "Cyber2A Workshop",
    "section": "Registration and Fees",
    "text": "Registration and Fees\nRegistration Process: Participants will be selected based on responses to questions in the workshop application (linked at the bottom of this page). Registration details will be provided to selected participants after the application period concludes.\nFees: Tuition is covered for the accepted participants by the Cyber2A award from NSF",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#instructors-and-speakers",
    "href": "workshop/index.html#instructors-and-speakers",
    "title": "Cyber2A Workshop",
    "section": "Instructors and Speakers",
    "text": "Instructors and Speakers\n\n\n\n\n\n\n\n\n\n\nWenwen Li\n\n\nProject Lead  Principal Investigator, NSF Award 2230034  Professor  Arizona State University  wenwen@asu.edu\n\n\n\n\n\n\n\n\n\n\n\n\nAnna Liljedahl\n\n\nPrincipal Investigator, NSF Award 2230035 Associate Scientist  Woodwell Climate Research Center aliljedahl@woodwellclimate.org\n\n\n\n\n\n\n\n\n\n\n\n\nMatthew Jones\n\n\nCo-Principal Investigator, NSF Award 2230034 Director of Research and Development, Informatics  National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara jones@nceas.ucsb.edu\n\n\n\n\n\n\n\n\n\n\n\n\nChia-Yu Hsu\n\n\nSenior Personnel Research Professional  Arizona State University chsu53@asu.edu\n\n\n\n\n\n\n\n\n\n\n\n\nMinu Mathew\n\n\nResearch Software Engineer  National Center for Supercomputing Applications(NCSA) at University of Illinois Urbana Champaign  minum@illinois.edu \n\n\n\n\n\n\n\n\n\n\n\n\nSandeep Puthanveetil Satheesan\n\n\nSenior Research Software Engineer  National Center for Supercomputing Applications, University of Illinois Urbana-Champaign  sandeeps@illinois.edu \n\n\n\n\n\n\n\n\n\n\n\n\nYili Yang\n\n\nData Scientist Specialist Woodwell Climate Research Center  yyang@woodwellclimate.org  https://www.woodwellclimate.org/staff/yili-yang/ \n\n\n\n\n\n\n\n\n\n\n\n\nChandi Witharana\n\n\nAssistant Professor  University of Connecticut  Chandi.Witharana@uconn.edu  https://nre.uconn.edu/chandi-witharana/\n\n\n\n\n\n\n\n\n\n\n\n\nBen Galewsky\n\n\nSr.¬†Research Software Engineer  National Center for Supercomputing Applications(NCSA) at University of Illinois Urbana Champaign  bengal1@illinois.edu \n\n\n\n\n\n\n\n\n\n\n\n\nNicole Greco\n\n\nCommunity Engagement & Outreach Coordinator  National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara  greco@nceas.ucsb.edu \n\n\n\n\n\n\n\n\n\n\n\n\nAlyona Kosobokova\n\n\nSenior Research Software Engineer  National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara \n\n\n\n\n\n\n\n\n\n\n\n\nJim Regetz\n\n\nDirector of Research Software Engineering  National Center for Ecological Analysis & Synthesis, University of California, Santa Barbara  regetz@nceas.ucsb.edu \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#workshop-schedule",
    "href": "workshop/index.html#workshop-schedule",
    "title": "Cyber2A Workshop",
    "section": "Workshop Schedule",
    "text": "Workshop Schedule",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#pre-workshop-preparation",
    "href": "workshop/index.html#pre-workshop-preparation",
    "title": "Cyber2A Workshop",
    "section": "Pre-Workshop Preparation",
    "text": "Pre-Workshop Preparation\nPrerequisites:\n\nBasic programming knowledge, preferably in Python\nMathematics background, including linear algebra, calculus, and statistics\nExperience with data manipulation using tools like Pandas, NumPy, etc.\nIntroductory knowledge of AI and machine learning concepts\n\nPreparation Materials: Please refer to the reference section of each workshop curriculum preview for review and further reading.",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#contact-information",
    "href": "workshop/index.html#contact-information",
    "title": "Cyber2A Workshop",
    "section": "Contact Information",
    "text": "Contact Information\nContact Person: WenWen Li, Arizona State University\nEmail: Please reach out to wenwen@asu.edu with any questions or concerns\nPhone: For urgent concerns, please contact 480-727-5987",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#additional-information",
    "href": "workshop/index.html#additional-information",
    "title": "Cyber2A Workshop",
    "section": "Additional Information",
    "text": "Additional Information\nAccommodations: Lodging will be covered by the Cyber2A award from NSF and will be located in Santa Barbara, CA. Additional information about lodging and transportation will be provided to accepted participants.\nPolicies: Please review the NCEAS Code of Conduct prior to applying for this workshop",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#workshop-application",
    "href": "workshop/index.html#workshop-application",
    "title": "Cyber2A Workshop",
    "section": "Workshop Application",
    "text": "Workshop Application\n**Applications for this workshop closed on August 1st, 2024\nDirect any issues or questions regarding the application to: greco@nceas.ucsb.edu",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/index.html#cyber2a-webinars",
    "href": "workshop/index.html#cyber2a-webinars",
    "title": "Cyber2A Workshop",
    "section": "Cyber2A Webinars",
    "text": "Cyber2A Webinars\nUpcoming webinars will be posted here as they are organized",
    "crumbs": [
      "Workshop",
      "Workshop Information"
    ]
  },
  {
    "objectID": "workshop/preview/ai-for-everyone.html",
    "href": "workshop/preview/ai-for-everyone.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session aims to introduce AI to a non-specialist audience, ensuring that participants from any background can understand these essential concepts. The focus will be on explaining key terminology and the basic principles of machine learning and deep learning. By the end of this session, participants will have a solid foundational knowledge of key AI concepts, enabling them to better appreciate and engage with more advanced topics in the following sessions.\n\n\n\nML, DL, NN, CNN, datasets and annotations, training and inference, accuracy and validation, supervised learning, etc.\n\n\n\n\n\n\nWhat is AI?\n\nDefinition and core concepts.\nBrief history and its role in modern research.\n\nKey takeaway: ‚Äì Artificial Intelligence as a tool, that helps you find insight and patterns in data by applying specific types of algorithms. ‚Äì Artificial Intelligence can be useful during not only the data analysis phase of a scientific method but every step from generating a hypothesis to publishing results. (Let‚Äôs find out how together)\n\n\n\n\n\nSupervised vs.¬†Unsupervised Learning\n\nDefinitions and examples of each.\nWhen to use them in scientific research.\n\nTechniques Overview\n\nMachine Learning (ML)\nDeep Learning (DL)\nNatural Language Processing (NLP)\n\nKey takeaway: Different types and techniques of AI can be applied depending on the type of data and research questions.\n\n\n\n\n\nImportance of Data\n\nHow AI models depend on good data (quality over quantity).\n\nTypes of Datasets\n\nStructured vs.¬†unstructured data.\nExamples relevant to Arctic science.\n\nKey takeaway: Data is the foundation of AI; understanding it improves AI‚Äôs accuracy and usefulness.\n\n\n\n\n\nIntroduction to a Dataset\n\nStep-by-step Model Creation (Python)\n\nTesting and Evaluating Results\n\nShow how to evaluate the performance of the model.\n\nKey takeaway: Building an AI model is more accessible than it seems, even for beginners.\n\n\n\n\n\nEmerging AI Trends\n\n\n\n\n\nDiscussion:\n\nLet‚Äôs think about specific Arctic science-related problems.\nExplore how AI might help address these problems.\nKey takeaway: AI can be applied at every stage of scientific research.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI for everyone: an introductory overview"
    ]
  },
  {
    "objectID": "workshop/preview/ai-for-everyone.html#goal",
    "href": "workshop/preview/ai-for-everyone.html#goal",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session aims to introduce AI to a non-specialist audience, ensuring that participants from any background can understand these essential concepts. The focus will be on explaining key terminology and the basic principles of machine learning and deep learning. By the end of this session, participants will have a solid foundational knowledge of key AI concepts, enabling them to better appreciate and engage with more advanced topics in the following sessions.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI for everyone: an introductory overview"
    ]
  },
  {
    "objectID": "workshop/preview/ai-for-everyone.html#key-elements",
    "href": "workshop/preview/ai-for-everyone.html#key-elements",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "ML, DL, NN, CNN, datasets and annotations, training and inference, accuracy and validation, supervised learning, etc.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI for everyone: an introductory overview"
    ]
  },
  {
    "objectID": "workshop/preview/ai-for-everyone.html#outline",
    "href": "workshop/preview/ai-for-everyone.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "What is AI?\n\nDefinition and core concepts.\nBrief history and its role in modern research.\n\nKey takeaway: ‚Äì Artificial Intelligence as a tool, that helps you find insight and patterns in data by applying specific types of algorithms. ‚Äì Artificial Intelligence can be useful during not only the data analysis phase of a scientific method but every step from generating a hypothesis to publishing results. (Let‚Äôs find out how together)\n\n\n\n\n\nSupervised vs.¬†Unsupervised Learning\n\nDefinitions and examples of each.\nWhen to use them in scientific research.\n\nTechniques Overview\n\nMachine Learning (ML)\nDeep Learning (DL)\nNatural Language Processing (NLP)\n\nKey takeaway: Different types and techniques of AI can be applied depending on the type of data and research questions.\n\n\n\n\n\nImportance of Data\n\nHow AI models depend on good data (quality over quantity).\n\nTypes of Datasets\n\nStructured vs.¬†unstructured data.\nExamples relevant to Arctic science.\n\nKey takeaway: Data is the foundation of AI; understanding it improves AI‚Äôs accuracy and usefulness.\n\n\n\n\n\nIntroduction to a Dataset\n\nStep-by-step Model Creation (Python)\n\nTesting and Evaluating Results\n\nShow how to evaluate the performance of the model.\n\nKey takeaway: Building an AI model is more accessible than it seems, even for beginners.\n\n\n\n\n\nEmerging AI Trends\n\n\n\n\n\nDiscussion:\n\nLet‚Äôs think about specific Arctic science-related problems.\nExplore how AI might help address these problems.\nKey takeaway: AI can be applied at every stage of scientific research.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI for everyone: an introductory overview"
    ]
  },
  {
    "objectID": "workshop/preview/ai-workflows-and-mlops.html",
    "href": "workshop/preview/ai-workflows-and-mlops.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Ben Galewsky, Sr.¬†Research Software Engineer National Center for Supercomputing Applications (NCSA) University of Illinois Urbana-Champaign\n\n\nMachine learning models have become a vital tool for most branches of science. The process and tools for training these models on the lab‚Äôs desktop is often fragile, slow, and not reproducible. In this workshop, we will introduce the concept of MLOps, which is a set of practices that aims to streamline the process of developing, training, and deploying machine learning models. We will use the popular open source MLOps tool, MLflow, to demonstrate how to track experiments, package code, and deploy models. We will also introduce Garden, a tool that allows researchers to publish ML Models as citable objects.\n\n\n\n\nIntroduction to MLOps\nIntroduction to MLflow\nTracking experiments with MLflow\nPackaging code with MLflow\nDeploying models with MLflow\nPublishing models with Garden\n\n\n\n\n\nMLflow\nGarden",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI workflows and MLOps: from development to deployment"
    ]
  },
  {
    "objectID": "workshop/preview/ai-workflows-and-mlops.html#overview",
    "href": "workshop/preview/ai-workflows-and-mlops.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Machine learning models have become a vital tool for most branches of science. The process and tools for training these models on the lab‚Äôs desktop is often fragile, slow, and not reproducible. In this workshop, we will introduce the concept of MLOps, which is a set of practices that aims to streamline the process of developing, training, and deploying machine learning models. We will use the popular open source MLOps tool, MLflow, to demonstrate how to track experiments, package code, and deploy models. We will also introduce Garden, a tool that allows researchers to publish ML Models as citable objects.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI workflows and MLOps: from development to deployment"
    ]
  },
  {
    "objectID": "workshop/preview/ai-workflows-and-mlops.html#outline",
    "href": "workshop/preview/ai-workflows-and-mlops.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Introduction to MLOps\nIntroduction to MLflow\nTracking experiments with MLflow\nPackaging code with MLflow\nDeploying models with MLflow\nPublishing models with Garden",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI workflows and MLOps: from development to deployment"
    ]
  },
  {
    "objectID": "workshop/preview/ai-workflows-and-mlops.html#reference",
    "href": "workshop/preview/ai-workflows-and-mlops.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "MLflow\nGarden",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ AI workflows and MLOps: from development to deployment"
    ]
  },
  {
    "objectID": "workshop/preview/foundation-models.html",
    "href": "workshop/preview/foundation-models.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Foundation models (FM) are deep learning models trained on massive raw unlabelled datasets usually through self-supervised learning. FMs enable today‚Äôs data scientists to use them as the base and fine-tune using domain specific data to obtain models that can handle a wide range of tasks [1, 6, 7]. In this talk, we provide an introduction to FMs, its history, evolution, and go through its key features and categories, and a few examples. We also briefly discuss how foundation models work. This talk will be a precursor to the hands-on session that follows on the same topic.\n Image source: 2021 paper on foundation models by Stanford researchers [1].\nIn this session, we take a closer look at what constitutes a foundation model, a few examples, and some basic principles around how it works.\n\n\n\n\nIntroduction to foundation models, its history and evolution\nKey features of foundation models\nTypes of foundation models: Language, Vision, Generative, and Multimodal\nExamples of foundation models: BERT [3], GPT [4], YOLO [2], SAM [5], DALLE-2\nHow do foundation models work?\n\n\n\n\n\nOn the opportunities and risk of Foundation models\nYou Only Look Once\nBERT\nGPT3\nSegment Anything Model\nNVIDIA blog post on foundation models\nWhat are Foundation Models? - Generative AI",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Foundation models: the cornerstones of modern AI"
    ]
  },
  {
    "objectID": "workshop/preview/foundation-models.html#overview",
    "href": "workshop/preview/foundation-models.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Foundation models (FM) are deep learning models trained on massive raw unlabelled datasets usually through self-supervised learning. FMs enable today‚Äôs data scientists to use them as the base and fine-tune using domain specific data to obtain models that can handle a wide range of tasks [1, 6, 7]. In this talk, we provide an introduction to FMs, its history, evolution, and go through its key features and categories, and a few examples. We also briefly discuss how foundation models work. This talk will be a precursor to the hands-on session that follows on the same topic.\n Image source: 2021 paper on foundation models by Stanford researchers [1].\nIn this session, we take a closer look at what constitutes a foundation model, a few examples, and some basic principles around how it works.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Foundation models: the cornerstones of modern AI"
    ]
  },
  {
    "objectID": "workshop/preview/foundation-models.html#outline",
    "href": "workshop/preview/foundation-models.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Introduction to foundation models, its history and evolution\nKey features of foundation models\nTypes of foundation models: Language, Vision, Generative, and Multimodal\nExamples of foundation models: BERT [3], GPT [4], YOLO [2], SAM [5], DALLE-2\nHow do foundation models work?",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Foundation models: the cornerstones of modern AI"
    ]
  },
  {
    "objectID": "workshop/preview/foundation-models.html#reference",
    "href": "workshop/preview/foundation-models.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "On the opportunities and risk of Foundation models\nYou Only Look Once\nBERT\nGPT3\nSegment Anything Model\nNVIDIA blog post on foundation models\nWhat are Foundation Models? - Generative AI",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Foundation models: the cornerstones of modern AI"
    ]
  },
  {
    "objectID": "workshop/preview/guest-lecture-yili-rts-introduction.html",
    "href": "workshop/preview/guest-lecture-yili-rts-introduction.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "In this session, we will introduce and explore the Arctic Retrogressive Thaw Slump (ARTS) dataset. We aim to illuminate the background and motivation behind the ARTS dataset, detail its design elements including functions, metadata, and usage, and underscore its defining features such as scalability, scientific integrity, and the potential for community contribution.\n\n\n\n\nBackground and motivation of the Arctic\nRetrogressive Thaw Slump (ARTS) data set.\nSource data for the ARTS data set\nDesign of the data set - functions, metadata, usage\nFeatures of the data set - scalable, scientific, contributable\nData Curation Framework - standards, protocols\nThe ARTS repository - user and contributor guideline\nQuestions and discussions\n\n\n\n\n\nhttps://github.com/whrc/ARTS",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Guest lecture: unveiling the ARTS dataset for a thawing frontier"
    ]
  },
  {
    "objectID": "workshop/preview/guest-lecture-yili-rts-introduction.html#overview",
    "href": "workshop/preview/guest-lecture-yili-rts-introduction.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "In this session, we will introduce and explore the Arctic Retrogressive Thaw Slump (ARTS) dataset. We aim to illuminate the background and motivation behind the ARTS dataset, detail its design elements including functions, metadata, and usage, and underscore its defining features such as scalability, scientific integrity, and the potential for community contribution.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Guest lecture: unveiling the ARTS dataset for a thawing frontier"
    ]
  },
  {
    "objectID": "workshop/preview/guest-lecture-yili-rts-introduction.html#outline",
    "href": "workshop/preview/guest-lecture-yili-rts-introduction.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Background and motivation of the Arctic\nRetrogressive Thaw Slump (ARTS) data set.\nSource data for the ARTS data set\nDesign of the data set - functions, metadata, usage\nFeatures of the data set - scalable, scientific, contributable\nData Curation Framework - standards, protocols\nThe ARTS repository - user and contributor guideline\nQuestions and discussions",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Guest lecture: unveiling the ARTS dataset for a thawing frontier"
    ]
  },
  {
    "objectID": "workshop/preview/guest-lecture-yili-rts-introduction.html#reference",
    "href": "workshop/preview/guest-lecture-yili-rts-introduction.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "https://github.com/whrc/ARTS",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Guest lecture: unveiling the ARTS dataset for a thawing frontier"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-mmsegmentation.html",
    "href": "workshop/preview/hands-on-lab-mmsegmentation.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This hands-on lab session provides participants with practical experience using MMSegmentation to perform semantic segmentation tasks. Participants will engage in guided exercises that build on the concepts introduced in the previous session, applying MMSegmentation to real-world datasets relevant to Arctic research. By the end of this session, participants will have gained the practical skills necessary to implement and fine-tune semantic segmentation models using MMSegmentation, enabling them to effectively apply these techniques in their own research projects.\n\n\n\n\nRecap of MMSegmentation core functionalities\nGuided exercise 1: preparing and loading data\nGuided exercise 2: building and training a semantic segmentation model\nGuided exercise 3: evaluating and fine-tuning the model\nWorking with real-world datasets: Arctic research applications\nTroubleshooting and optimization tips\nConclusion and Q&A\n\n\n\n\n\nhttps://mmsegmentation.readthedocs.io/en/latest/user_guides/index.html",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: MMSegmentation"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-mmsegmentation.html#overview",
    "href": "workshop/preview/hands-on-lab-mmsegmentation.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This hands-on lab session provides participants with practical experience using MMSegmentation to perform semantic segmentation tasks. Participants will engage in guided exercises that build on the concepts introduced in the previous session, applying MMSegmentation to real-world datasets relevant to Arctic research. By the end of this session, participants will have gained the practical skills necessary to implement and fine-tune semantic segmentation models using MMSegmentation, enabling them to effectively apply these techniques in their own research projects.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: MMSegmentation"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-mmsegmentation.html#outline",
    "href": "workshop/preview/hands-on-lab-mmsegmentation.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Recap of MMSegmentation core functionalities\nGuided exercise 1: preparing and loading data\nGuided exercise 2: building and training a semantic segmentation model\nGuided exercise 3: evaluating and fine-tuning the model\nWorking with real-world datasets: Arctic research applications\nTroubleshooting and optimization tips\nConclusion and Q&A",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: MMSegmentation"
    ]
  },
  {
    "objectID": "workshop/preview/hands-on-lab-mmsegmentation.html#reference",
    "href": "workshop/preview/hands-on-lab-mmsegmentation.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "https://mmsegmentation.readthedocs.io/en/latest/user_guides/index.html",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Hands-on-lab: MMSegmentation"
    ]
  },
  {
    "objectID": "workshop/preview/intro-to-dl-libraries-for-image-analysis.html",
    "href": "workshop/preview/intro-to-dl-libraries-for-image-analysis.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "his session introduces participants to MMSegmentation, a specialized deep learning library designed for semantic segmentation tasks. Participants will explore the unique capabilities of MMSegmentation in handling sophisticated image analysis projects. The session will cover how to navigate the library, implement advanced features, and apply them to real-world datasets, particularly in the context of Arctic research. While the focus will be on MMSegmentation, Detectron2 will also be mentioned as another powerful tool for image analysis. By the end of this session, participants will have a theoretical understanding of MMSegmentation and be prepared for a more extensive hands-on lab session.\n\n\n\n\nIntroduction to MMSegmentation: features and capabilities\nNavigating MMSegmentation: tools and techniques\nImplementing semantic segmentation with MMSegmentation\nPractical applications in Arctic research\nBrief overview of Detectron2 for comparison\nConclusion and Q&A\n\n\n\n\n\nhttps://github.com/open-mmlab/mmsegmentation\nhttps://github.com/facebookresearch/detectron2 (for further exploration)",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Introduction to deep learning libraries for image analysis"
    ]
  },
  {
    "objectID": "workshop/preview/intro-to-dl-libraries-for-image-analysis.html#overview",
    "href": "workshop/preview/intro-to-dl-libraries-for-image-analysis.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "his session introduces participants to MMSegmentation, a specialized deep learning library designed for semantic segmentation tasks. Participants will explore the unique capabilities of MMSegmentation in handling sophisticated image analysis projects. The session will cover how to navigate the library, implement advanced features, and apply them to real-world datasets, particularly in the context of Arctic research. While the focus will be on MMSegmentation, Detectron2 will also be mentioned as another powerful tool for image analysis. By the end of this session, participants will have a theoretical understanding of MMSegmentation and be prepared for a more extensive hands-on lab session.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Introduction to deep learning libraries for image analysis"
    ]
  },
  {
    "objectID": "workshop/preview/intro-to-dl-libraries-for-image-analysis.html#outline",
    "href": "workshop/preview/intro-to-dl-libraries-for-image-analysis.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Introduction to MMSegmentation: features and capabilities\nNavigating MMSegmentation: tools and techniques\nImplementing semantic segmentation with MMSegmentation\nPractical applications in Arctic research\nBrief overview of Detectron2 for comparison\nConclusion and Q&A",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Introduction to deep learning libraries for image analysis"
    ]
  },
  {
    "objectID": "workshop/preview/intro-to-dl-libraries-for-image-analysis.html#reference",
    "href": "workshop/preview/intro-to-dl-libraries-for-image-analysis.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "https://github.com/open-mmlab/mmsegmentation\nhttps://github.com/facebookresearch/detectron2 (for further exploration)",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Introduction to deep learning libraries for image analysis"
    ]
  },
  {
    "objectID": "workshop/preview/reproducibility.html",
    "href": "workshop/preview/reproducibility.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session aims to highlight the importance of reproducibility in AI-driven Arctic research. Participants will learn about the challenges and best practices for ensuring that AI models and their results can be reproduced by other researchers, a cornerstone for building trust and advancing the field. The discussion will cover strategies for documenting experiments, sharing data and code, and using version control systems.\n\n\n\n\nThe Reproducibility Checklist\nSharing Code\nModel Repositories\nVersion Control\nLEGO Activity\n\n\n\n\nGundersen, Odd Erik, and Sigbj√∏rn Kjensmo. 2018. ‚ÄúState of the Art: Reproducibility in Artificial Intelligence‚Äù. Proceedings of the AAAI Conference on Artificial Intelligence 32 (1). https://doi.org/10.1609/aaai.v32i1.11503.\nGundersen, Odd Erik, Yolanda Gil, and David W. Aha. ‚ÄúOn Reproducible AI: Towards Reproducible Research, Open Science, and Digital Scholarship in AI Publications.‚Äù AI Magazine 39, no. 3 (September 28, 2018): 56‚Äì68. https://doi.org/10.1609/aimag.v39i3.2816.\n‚ÄúHow the AI Community Can Get Serious about Reproducibility.‚Äù Accessed September 18, 2024. https://ai.meta.com/blog/how-the-ai-community-can-get-serious-about-reproducibility/.\nAbid, Areeba. ‚ÄúAddressing ML‚Äôs Reproducibility Crisis.‚Äù Medium, January 7, 2021. https://towardsdatascience.com/addressing-mls-reproducibility-crisis-7d59e9ed050.\nPyTorch. ‚ÄúTowards Reproducible Research with PyTorch Hub.‚Äù Accessed September 18, 2024. https://pytorch.org/blog/towards-reproducible-research-with-pytorch-hub/.\nStojnic, Robert. ‚ÄúML Code Completeness Checklist.‚Äù PapersWithCode (blog), April 8, 2020. https://medium.com/paperswithcode/ml-code-completeness-checklist-e9127b168501.\nAkalin, Altuna. ‚ÄúScientific Data Analysis Pipelines and Reproducibility.‚Äù Medium, July 5, 2021. https://towardsdatascience.com/scientific-data-analysis-pipelines-and-reproducibility-75ff9df5b4c5.\nHashesh, Ahmed. ‚ÄúVersion Control for ML Models: What It Is and How To Implement It.‚Äù neptune.ai, July 22, 2022. https://neptune.ai/blog/version-control-for-ml-models.\nNCEAS Learning Hub: https://www.nceas.ucsb.edu/learning-hub",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Reproducibility"
    ]
  },
  {
    "objectID": "workshop/preview/reproducibility.html#goal",
    "href": "workshop/preview/reproducibility.html#goal",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session aims to highlight the importance of reproducibility in AI-driven Arctic research. Participants will learn about the challenges and best practices for ensuring that AI models and their results can be reproduced by other researchers, a cornerstone for building trust and advancing the field. The discussion will cover strategies for documenting experiments, sharing data and code, and using version control systems.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Reproducibility"
    ]
  },
  {
    "objectID": "workshop/preview/reproducibility.html#outline",
    "href": "workshop/preview/reproducibility.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "The Reproducibility Checklist\nSharing Code\nModel Repositories\nVersion Control\nLEGO Activity\n\n\n\n\nGundersen, Odd Erik, and Sigbj√∏rn Kjensmo. 2018. ‚ÄúState of the Art: Reproducibility in Artificial Intelligence‚Äù. Proceedings of the AAAI Conference on Artificial Intelligence 32 (1). https://doi.org/10.1609/aaai.v32i1.11503.\nGundersen, Odd Erik, Yolanda Gil, and David W. Aha. ‚ÄúOn Reproducible AI: Towards Reproducible Research, Open Science, and Digital Scholarship in AI Publications.‚Äù AI Magazine 39, no. 3 (September 28, 2018): 56‚Äì68. https://doi.org/10.1609/aimag.v39i3.2816.\n‚ÄúHow the AI Community Can Get Serious about Reproducibility.‚Äù Accessed September 18, 2024. https://ai.meta.com/blog/how-the-ai-community-can-get-serious-about-reproducibility/.\nAbid, Areeba. ‚ÄúAddressing ML‚Äôs Reproducibility Crisis.‚Äù Medium, January 7, 2021. https://towardsdatascience.com/addressing-mls-reproducibility-crisis-7d59e9ed050.\nPyTorch. ‚ÄúTowards Reproducible Research with PyTorch Hub.‚Äù Accessed September 18, 2024. https://pytorch.org/blog/towards-reproducible-research-with-pytorch-hub/.\nStojnic, Robert. ‚ÄúML Code Completeness Checklist.‚Äù PapersWithCode (blog), April 8, 2020. https://medium.com/paperswithcode/ml-code-completeness-checklist-e9127b168501.\nAkalin, Altuna. ‚ÄúScientific Data Analysis Pipelines and Reproducibility.‚Äù Medium, July 5, 2021. https://towardsdatascience.com/scientific-data-analysis-pipelines-and-reproducibility-75ff9df5b4c5.\nHashesh, Ahmed. ‚ÄúVersion Control for ML Models: What It Is and How To Implement It.‚Äù neptune.ai, July 22, 2022. https://neptune.ai/blog/version-control-for-ml-models.\nNCEAS Learning Hub: https://www.nceas.ucsb.edu/learning-hub",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ Reproducibility"
    ]
  },
  {
    "objectID": "workshop/preview/the-building-blocks-of-nn-and-dl.html",
    "href": "workshop/preview/the-building-blocks-of-nn-and-dl.html",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session aims to provide a comprehensive introduction to the fundamental components of neural networks and deep learning. Participants will explore the architecture of neural networks, including layers, neurons, weights, and activation functions, as well as the principles behind training models, such as loss functions and optimizers. The goal is to equip participants with a solid understanding of how neural networks are constructed and how they learn, paving the way for deeper dives into specific neural network models and applications in future sessions.\n\n\n\n\nFundamentals of neural network: history and evolution\nCore components: neurons, layers, and weights\nArchitecture of neural networks: layers and activation functions\nTraining neural networks: loss functions and optimizers\nConclusion and Q&A\n\n\n\n\n\nhttps://cs231n.stanford.edu",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ The building blocks of neural networks and deep learning"
    ]
  },
  {
    "objectID": "workshop/preview/the-building-blocks-of-nn-and-dl.html#overview",
    "href": "workshop/preview/the-building-blocks-of-nn-and-dl.html#overview",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "This session aims to provide a comprehensive introduction to the fundamental components of neural networks and deep learning. Participants will explore the architecture of neural networks, including layers, neurons, weights, and activation functions, as well as the principles behind training models, such as loss functions and optimizers. The goal is to equip participants with a solid understanding of how neural networks are constructed and how they learn, paving the way for deeper dives into specific neural network models and applications in future sessions.",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ The building blocks of neural networks and deep learning"
    ]
  },
  {
    "objectID": "workshop/preview/the-building-blocks-of-nn-and-dl.html#outline",
    "href": "workshop/preview/the-building-blocks-of-nn-and-dl.html#outline",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "Fundamentals of neural network: history and evolution\nCore components: neurons, layers, and weights\nArchitecture of neural networks: layers and activation functions\nTraining neural networks: loss functions and optimizers\nConclusion and Q&A",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ The building blocks of neural networks and deep learning"
    ]
  },
  {
    "objectID": "workshop/preview/the-building-blocks-of-nn-and-dl.html#reference",
    "href": "workshop/preview/the-building-blocks-of-nn-and-dl.html#reference",
    "title": "Cyber2A Workshop",
    "section": "",
    "text": "https://cs231n.stanford.edu",
    "crumbs": [
      "Workshop",
      "Workshop Curriculum Preview",
      "‚Ä¢ The building blocks of neural networks and deep learning"
    ]
  }
]